{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:\n",
    "        \n",
    "        PARK, JunHo, junho@ccnets.org\n",
    "\n",
    "        \n",
    "        KIM, JeongYoong, jeongyoong@ccnets.org\n",
    "        \n",
    "    COPYRIGHT (c) 2024. CCNets. All Rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "path_append = \"../\" # Go up one directory from where you are.\n",
    "sys.path.append(path_append) \n",
    "\n",
    "from nn.utils.init import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "from torchvision import transforms\n",
    "\n",
    "# import albumentations\n",
    "n_img_sz = 64\n",
    "# Load the CelebA dataset for training. Specify the root directory where the dataset is located\n",
    "trainset = dset.CelebA(root=path_append + '../data/celeba', split = \"train\", transform=transforms.Compose([\n",
    "                            transforms.Resize(n_img_sz), # Transformations include resizing the images to `n_img_sz`\n",
    "                            transforms.CenterCrop(n_img_sz), # Center cropping to the same size\n",
    "                            transforms.ToTensor(), # Converting the images to tensors,\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalizing the pixel values to have a mean and standard deviation of 0.5 across all channels.\n",
    "                        ]), download= True)\n",
    "\n",
    "testset = dset.CelebA(root=path_append + '../data/celeba', split = \"test\", transform=transforms.Compose([\n",
    "                            transforms.Resize(n_img_sz), # Transformations include resizing the images to `n_img_sz`\n",
    "                            transforms.CenterCrop(n_img_sz), # Center cropping to the same size\n",
    "                            transforms.ToTensor(), # Converting the images to tensors\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalizing the pixel values to have a mean and standard deviation of 0.5 across all channels.\n",
    "                        ]), download= True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.Subset(trainset, range(0, 40000))\n",
    "testset = torch.utils.data.Subset(testset, range(0, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', \n",
    "              'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', \n",
    "              'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard', \n",
    "              'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', \n",
    "              'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young' ]\n",
    "male_and_smiling_attributes = torch.tensor([label_list.index('Male'), label_list.index('Smiling')])\n",
    "eyeglasses_and_young_attributes = torch.tensor([label_list.index('Eyeglasses'), label_list.index('Young')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for CelebA dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CausalModelDataset(Dataset):\n",
    "    def __init__(self, dataset, selected_attributes):\n",
    "        self.dataset = dataset\n",
    "        self.selected_attributes = selected_attributes\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.dataset[index]\n",
    "        y = torch.index_select(y.unsqueeze(0), 1, self.selected_attributes).squeeze(0)\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "class EncodingDataset(Dataset):\n",
    "    def __init__(self, dataset, attributes, causal_model):\n",
    "        self.dataset = dataset\n",
    "        self.attributes = attributes\n",
    "        self.causal_model = causal_model\n",
    "\n",
    "        data_loader = DataLoader(dataset=dataset, batch_size=256, shuffle=False, drop_last=False)\n",
    "        list_encodings = []\n",
    "        list_labels = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                images = images.to(self.causal_model.device)\n",
    "                encodings = self.causal_model.explain(images).detach().cpu()\n",
    "                attributes = labels[:, self.attributes]\n",
    "                list_encodings.append(encodings)\n",
    "                list_labels.append(attributes)\n",
    "        self.encodings = torch.cat(list_encodings, dim=0)\n",
    "        self.labels = torch.cat(list_labels, dim=0)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.encodings[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.setting.ml_params import MLParameters\n",
    "from tools.setting.data_config import DataConfig\n",
    "from trainer_hub import TrainerHub\n",
    "num_classes = 2\n",
    "data_config = DataConfig(dataset_name = 'celebA', task_type='multi_label_classification', obs_shape=[3, n_img_sz, n_img_sz], \\\n",
    "                        label_size=num_classes)\n",
    "\n",
    "#  Set training configuration from the AlgorithmConfig class, returning them as a Namespace object.\n",
    "ml_params = MLParameters(ccnet_network = 'resnet')\n",
    "\n",
    "ml_params.training.num_epoch = 3\n",
    "ml_params.model.ccnet_config.num_layers = 4\n",
    "ml_params.algorithm.reset_pretrained = True\n",
    "\n",
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.tabnet import TabNet \n",
    "from tools.setting.ml_params import ModelConfig\n",
    "\n",
    "class AttributeClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers=3, hidden_size=256):\n",
    "        super(AttributeClassifier, self).__init__()\n",
    "        \n",
    "        model_config = ModelConfig('tabnet')\n",
    "        model_config.num_layers = num_layers\n",
    "        model_config.d_model = hidden_size\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Create a list to hold all layers\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(input_size, hidden_size))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        ## Add TabNet layers\n",
    "        layers.append(TabNet(model_config))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        # Register all layers\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train classifier\n",
    "DECAY_RATE = 0.01\n",
    "ITERATION_100K = 100000\n",
    "gamma = pow(DECAY_RATE, 1 / ITERATION_100K)    \n",
    "\n",
    "def train_classifier(model, trainset, num_epochs=3, gamma=gamma):\n",
    "    model.train()\n",
    "    train_loader = DataLoader(trainset, batch_size=64, shuffle=True)    \n",
    "    len_loader = len(train_loader)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "    for epoch in range(num_epochs):\n",
    "        sum_loss = 0\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            sum_loss += loss.item()\n",
    "        print(\"Epoch: \", epoch, \"Loss: \", sum_loss / len_loader)\n",
    "    print(\"Learning rate: \", optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to evaluate classifier\n",
    "def test_classifier(model, dataset):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device).float()\n",
    "            outputs = model(data)\n",
    "            preds = torch.sigmoid(outputs).round()\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def plot_accuracy(ax, epochs, selected_results_dict, none_selected_results_dict):\n",
    "    ax.cla()\n",
    "    ax.plot(epochs, selected_results_dict['accuracy'], label='Selected Attributes Accuracy')\n",
    "    ax.plot(epochs, none_selected_results_dict['accuracy'], label='None Selected Attributes Accuracy')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('None Selected Attribute score should be higher')\n",
    "    ax.legend()\n",
    "\n",
    "def plot_f1_score(ax, epochs, selected_results_dict, none_selected_results_dict):\n",
    "    ax.cla()\n",
    "    ax.plot(epochs, selected_results_dict['f1_score'], label='Selected Attributes F1 Score')\n",
    "    ax.plot(epochs, none_selected_results_dict['f1_score'], label='None Selected Attributes F1 Score')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('F1 Score')\n",
    "    ax.set_title('Selected Attribute score should be lower')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer Name: causal_trainer\n",
      "\n",
      "\n",
      "\u001b[1mModelParameters Parameters:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccnet_config</th>\n",
       "      <th>ccnet_network</th>\n",
       "      <th>encoder_config</th>\n",
       "      <th>encoder_network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>See details below</td>\n",
       "      <td>resnet</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ccnet_config ccnet_network encoder_config encoder_network\n",
       "0  See details below        resnet           None            none"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m\n",
      "Detailed ccnet_config Configuration:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccnet_config_model_name</th>\n",
       "      <th>ccnet_config_num_layers</th>\n",
       "      <th>ccnet_config_d_model</th>\n",
       "      <th>ccnet_config_dropout</th>\n",
       "      <th>ccnet_config_obs_shape</th>\n",
       "      <th>ccnet_config_condition_dim</th>\n",
       "      <th>ccnet_config_z_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[3, 64, 64]</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ccnet_config_model_name  ccnet_config_num_layers  ccnet_config_d_model  \\\n",
       "0                  resnet                        4                   256   \n",
       "\n",
       "   ccnet_config_dropout ccnet_config_obs_shape  ccnet_config_condition_dim  \\\n",
       "0                  0.05            [3, 64, 64]                           2   \n",
       "\n",
       "   ccnet_config_z_dim  \n",
       "0                 128  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrainingParameters Parameters:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>max_iters</th>\n",
       "      <th>max_seq_len</th>\n",
       "      <th>min_seq_len</th>\n",
       "      <th>num_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>100000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  max_iters max_seq_len min_seq_len  num_epoch\n",
       "0          64     100000        None        None          3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOptimizationParameters Parameters:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_grad_range</th>\n",
       "      <th>decay_rate_100k</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_grad_norm</th>\n",
       "      <th>scheduler_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clip_grad_range  decay_rate_100k  learning_rate  max_grad_norm  \\\n",
       "0            None             0.05         0.0002            1.0   \n",
       "\n",
       "  scheduler_type  \n",
       "0    exponential  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAlgorithmParameters Parameters:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enable_diffusion</th>\n",
       "      <th>error_function</th>\n",
       "      <th>reset_pretrained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>mse</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enable_diffusion error_function  reset_pretrained\n",
       "0             False            mse              True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataConfig Parameters:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>task_type</th>\n",
       "      <th>obs_shape</th>\n",
       "      <th>label_size</th>\n",
       "      <th>explain_size</th>\n",
       "      <th>explain_layer</th>\n",
       "      <th>state_size</th>\n",
       "      <th>show_image_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>celeba</td>\n",
       "      <td>multi_label_classification</td>\n",
       "      <td>[3, 64, 64]</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name                   task_type    obs_shape  label_size  \\\n",
       "0       celeba  multi_label_classification  [3, 64, 64]           2   \n",
       "\n",
       "   explain_size explain_layer state_size show_image_indices  \n",
       "0           128          tanh       None               None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "trainer_hub = TrainerHub(ml_params, data_config, device, use_print = True)\n",
    "encoding_size = data_config.explain_size\n",
    "causal_model = trainer_hub.ccnet\n",
    "\n",
    "selected_classifier = AttributeClassifier(encoding_size, num_classes).to(device)\n",
    "none_selected_classifier = AttributeClassifier(encoding_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_classifiers(epoch, axs, testset_selected, testset_none_selected, selected_results, none_selected_results):\n",
    "    print(f\"Testing causal classifier on selected attributes at epoch {epoch}...\")\n",
    "    selected_acc, selected_f1 = test_classifier(selected_classifier, testset_selected)\n",
    "    selected_results['accuracy'].append(selected_acc)\n",
    "    selected_results['f1_score'].append(selected_f1)\n",
    "\n",
    "    print(f\"Testing classifier on none selected attributes at epoch {epoch}...\")\n",
    "    none_selected_acc, none_selected_f1 = test_classifier(none_selected_classifier, testset_none_selected)\n",
    "    none_selected_results['accuracy'].append(none_selected_acc)\n",
    "    none_selected_results['f1_score'].append(none_selected_f1)\n",
    "\n",
    "    # Update plots\n",
    "    epochs = range(1, len(selected_results['accuracy']) + 1)\n",
    "    \n",
    "    plot_accuracy(axs[0], epochs, selected_results, none_selected_results)\n",
    "    plot_f1_score(axs[1], epochs, selected_results, none_selected_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_plot(fig):\n",
    "    plt.tight_layout()\n",
    "    clear_output(wait=True)\n",
    "    display(fig, display_id='fig')\n",
    "    plt.pause(0.1)  # Pause to allow the plot to update\n",
    "\n",
    "def update_annot(ind, line, annot):\n",
    "    pos = line.get_offsets()[ind[\"ind\"][0]]\n",
    "    annot.xy = pos\n",
    "    text = f\"{pos[0]:.2f}, {pos[1]:.2f}\"\n",
    "    annot.set_text(text)\n",
    "    annot.get_bbox_patch().set_alpha(0.4)\n",
    "\n",
    "def hover(event, fig, ax, line, annot):\n",
    "    vis = annot.get_visible()\n",
    "    if event.inaxes == ax:\n",
    "        cont, ind = line.contains(event)\n",
    "        if cont:\n",
    "            update_annot(ind, line, annot)\n",
    "            annot.set_visible(True)\n",
    "            fig.canvas.draw_idle()\n",
    "        else:\n",
    "            if vis:\n",
    "                annot.set_visible(False)\n",
    "                fig.canvas.draw_idle()\n",
    "\n",
    "def initialize_plot():\n",
    "    # Sample data\n",
    "    x = np.linspace(0, 10, 100)\n",
    "    y = np.sin(x)\n",
    "    \n",
    "    # Turn off interactive mode initially\n",
    "    plt.ioff()\n",
    "    \n",
    "    # Create the figure and axes\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Create the scatter plot on the first subplot\n",
    "    ax = axs[0]\n",
    "    line = ax.scatter(x, y)\n",
    "    \n",
    "    # Annotate point\n",
    "    annot = ax.annotate(\"\", xy=(0,0), xytext=(20,20),\n",
    "                        textcoords=\"offset points\",\n",
    "                        bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                        arrowprops=dict(arrowstyle=\"->\"))\n",
    "    annot.set_visible(False)\n",
    "    \n",
    "    # Connect the hover event\n",
    "    fig.canvas.mpl_connect(\"motion_notify_event\", lambda event: hover(event, fig, ax, line, annot))\n",
    "\n",
    "    return fig, axs, ax, line, annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_causal_model_and_classifiers(causal_model_selected_attributes, none_selected_attributes, num_epoch):\n",
    "    causal_model_dataset = CausalModelDataset(trainset, causal_model_selected_attributes)\n",
    "    \n",
    "    # Initialize the plot\n",
    "    fig, axs, ax, line, annot = initialize_plot()\n",
    "    \n",
    "    # Create dictionaries to store results\n",
    "    selected_results_dict = {'accuracy': [], 'f1_score': []}\n",
    "    none_selected_results_dict = {'accuracy': [], 'f1_score': []}\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        if epoch > 0:\n",
    "            print(f\"Training causal model at epoch {epoch}...\")\n",
    "            trainer_hub.train(causal_model_dataset)\n",
    "        \n",
    "        # Train and evaluate classifiers on the explanation datasets\n",
    "        print(\"Training causal classifier on selected attributes...\")\n",
    "        trainset_selected_attributes = EncodingDataset(trainset, causal_model_selected_attributes, causal_model)\n",
    "        testset_selected_attributes = EncodingDataset(testset, causal_model_selected_attributes, causal_model)\n",
    "\n",
    "        train_classifier(selected_classifier, trainset_selected_attributes)\n",
    "\n",
    "        print(\"Training classifier on none selected attributes...\")\n",
    "        trainset_none_selected_attributes = EncodingDataset(trainset, none_selected_attributes, causal_model)\n",
    "        testset_none_selected_attributes = EncodingDataset(testset, none_selected_attributes, causal_model)    \n",
    "        \n",
    "        train_classifier(none_selected_classifier, trainset_none_selected_attributes)\n",
    "        \n",
    "        # Test classifiers\n",
    "        test_classifiers(epoch, axs, testset_selected_attributes, testset_none_selected_attributes, selected_results_dict, none_selected_results_dict)\n",
    "        \n",
    "        # Update the plot\n",
    "        display_plot(fig)\n",
    "\n",
    "    plt.ioff()  # Turn off interactive mode\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training causal classifier on selected attributes...\n"
     ]
    }
   ],
   "source": [
    "train_causal_model_and_classifiers(causal_model_selected_attributes = eyeglasses_and_young_attributes, none_selected_attributes = male_and_smiling_attributes, num_epoch = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_causal_model_and_classifiers(causal_model_selected_attributes = male_and_smiling_attributes, none_selected_attributes = eyeglasses_and_young_attributes, num_epoch = 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
