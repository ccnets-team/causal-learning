{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:\n",
    "        \n",
    "        PARK, JunHo, junho@ccnets.org\n",
    "\n",
    "        \n",
    "        KIM, JeongYoong, jeongyoong@ccnets.org\n",
    "        \n",
    "    COPYRIGHT (c) 2024. CCNets. All Rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "path_append = \"../\" # Go up one directory from where you are.\n",
    "sys.path.append(path_append) \n",
    "\n",
    "from nn.utils.init import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "from torchvision import transforms\n",
    "\n",
    "# import albumentations\n",
    "n_img_sz = 64\n",
    "# Load the CelebA dataset for training. Specify the root directory where the dataset is located\n",
    "trainset = dset.CelebA(root=path_append + '../data/celeba', split = \"train\", transform=transforms.Compose([\n",
    "                            transforms.Resize(n_img_sz), # Transformations include resizing the images to `n_img_sz`\n",
    "                            transforms.CenterCrop(n_img_sz), # Center cropping to the same size\n",
    "                            transforms.ToTensor(), # Converting the images to tensors,\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalizing the pixel values to have a mean and standard deviation of 0.5 across all channels.\n",
    "                        ]), download= True)\n",
    "\n",
    "testset = dset.CelebA(root=path_append + '../data/celeba', split = \"test\", transform=transforms.Compose([\n",
    "                            transforms.Resize(n_img_sz), # Transformations include resizing the images to `n_img_sz`\n",
    "                            transforms.CenterCrop(n_img_sz), # Center cropping to the same size\n",
    "                            transforms.ToTensor(), # Converting the images to tensors\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalizing the pixel values to have a mean and standard deviation of 0.5 across all channels.\n",
    "                        ]), download= True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = torch.utils.data.Subset(trainset, range(0, 40000))\n",
    "testset = torch.utils.data.Subset(testset, range(0, 10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', \n",
    "              'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', \n",
    "              'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard', \n",
    "              'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', \n",
    "              'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young' ]\n",
    "\n",
    "male_and_smiling_attributes = torch.tensor([label_list.index('Male'), label_list.index('Smiling')])\n",
    "eyeglasses_and_young_attributes = torch.tensor([label_list.index('Eyeglasses'), label_list.index('Young')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for CelebA dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CausalModelDataset(Dataset):\n",
    "    def __init__(self, dataset, selected_attributes):\n",
    "        self.dataset = dataset\n",
    "        self.selected_attributes = selected_attributes\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.dataset[index]\n",
    "        y = torch.index_select(y.unsqueeze(0), 1, self.selected_attributes).squeeze(0)\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "class EncodingDataset(Dataset):\n",
    "    def __init__(self, dataset, attributes, causal_model):\n",
    "        self.dataset = dataset\n",
    "        self.attributes = attributes\n",
    "        self.causal_model = causal_model\n",
    "\n",
    "        data_loader = DataLoader(dataset=dataset, batch_size=256, shuffle=False, drop_last=False)\n",
    "        list_encodings = []\n",
    "        list_labels = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                images = images.to(self.causal_model.device)\n",
    "                encodings = self.causal_model.explain(images).detach().cpu()\n",
    "                attributes = labels[:, self.attributes]\n",
    "                list_encodings.append(encodings)\n",
    "                list_labels.append(attributes)\n",
    "        self.encodings = torch.cat(list_encodings, dim=0)\n",
    "        self.labels = torch.cat(list_labels, dim=0)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.encodings[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.setting.ml_params import MLParameters\n",
    "from tools.setting.data_config import DataConfig\n",
    "from trainer_hub import TrainerHub\n",
    "num_classes = 2\n",
    "data_config = DataConfig(dataset_name = 'celebA', task_type='multi_label_classification', obs_shape=[3, n_img_sz, n_img_sz], \\\n",
    "                        label_size=num_classes)\n",
    "\n",
    "#  Set training configuration from the AlgorithmConfig class, returning them as a Namespace object.\n",
    "ml_params = MLParameters(ccnet_network = 'resnet')\n",
    "\n",
    "ml_params.training.num_epoch = 1\n",
    "ml_params.model.ccnet_config.num_layers = 4\n",
    "ml_params.algorithm.reset_pretrained = True\n",
    "\n",
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.tabnet import TabNet \n",
    "from tools.setting.ml_params import ModelConfig\n",
    "\n",
    "class AttributeClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers=3, hidden_size=256):\n",
    "        super(AttributeClassifier, self).__init__()\n",
    "        \n",
    "        model_config = ModelConfig('tabnet')\n",
    "        model_config.num_layers = num_layers\n",
    "        model_config.d_model = hidden_size\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Create a list to hold all layers\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(input_size, hidden_size))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        ## Add TabNet layers\n",
    "        layers.append(TabNet(model_config))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        # Register all layers\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train classifier\n",
    "DECAY_RATE = 0.01\n",
    "ITERATION_100K = 100000\n",
    "gamma = pow(DECAY_RATE, 1 / ITERATION_100K)    \n",
    "\n",
    "def train_classifier(model, trainset, num_epochs=5, gamma=gamma):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loader = DataLoader(trainset, batch_size=64, shuffle=True)    \n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "    print(\"Learning rate: \", optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to evaluate classifier\n",
    "def test_classifier(model, dataset, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device).float()\n",
    "            outputs = model(data)\n",
    "            preds = torch.sigmoid(outputs).round()\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    return accuracy, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot accuracy\n",
    "def plot_accuracy(ax, epochs, selected_results_dict, none_selected_results_dict):\n",
    "    ax.cla()\n",
    "    ax.plot(epochs, selected_results_dict['accuracy'], label='Selected Attributes Accuracy')\n",
    "    ax.plot(epochs, none_selected_results_dict['accuracy'], label='None Selected Attributes Accuracy')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.set_title('None Selected Attributes should be Accurate')\n",
    "    ax.legend()\n",
    "\n",
    "# Function to plot F1 score\n",
    "def plot_f1_score(ax, epochs, selected_results_dict, none_selected_results_dict):\n",
    "    ax.cla()\n",
    "    ax.plot(epochs, selected_results_dict['f1_score'], label='Selected Attributes F1 Score')\n",
    "    ax.plot(epochs, none_selected_results_dict['f1_score'], label='None Selected Attributes F1 Score')\n",
    "    ax.set_xlabel('Epochs')\n",
    "    ax.set_ylabel('F1 Score')\n",
    "    ax.set_title('None Selected Attributes should be higher F1 Score')\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_classifiers(epoch, axs, selected_classifier, none_selected_classifier, testset_selected, testset_none_selected, selected_results_dict, none_selected_results_dict):\n",
    "    # Store and print results\n",
    "    print(f\"Testing causal classifier on selected attributes at epoch {epoch}...\")\n",
    "    set_random_seed(epoch)\n",
    "    selected_acc, selected_f1 = test_classifier(selected_classifier, testset_selected, device)\n",
    "    selected_results_dict['accuracy'].append(selected_acc)\n",
    "    selected_results_dict['f1_score'].append(selected_f1)\n",
    "    # print selected_acc, selected_f1\n",
    "    print(f\"Testing classifier on selected attributes accuracy {selected_acc}, f1 score {selected_f1}\")\n",
    "    print(f\"Testing classifier on none selected attributes at epoch {epoch}...\")\n",
    "    set_random_seed(epoch)\n",
    "    none_selected_acc, none_selected_f1 = test_classifier(none_selected_classifier, testset_none_selected, device)\n",
    "    none_selected_results_dict['accuracy'].append(none_selected_acc)\n",
    "    none_selected_results_dict['f1_score'].append(none_selected_f1)\n",
    "    print(f\"Testing classifier on none selected attributes accuracy {none_selected_acc}, f1 score {none_selected_f1}\")\n",
    "\n",
    "    # Update plots\n",
    "    epochs = range(1, epoch + 2)\n",
    "    \n",
    "    plot_accuracy(axs[0], epochs, selected_results_dict, none_selected_results_dict)\n",
    "    plot_f1_score(axs[1], epochs, selected_results_dict, none_selected_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def train_causal_model_and_classifiers(causal_model_selected_attributes, causal_model_none_selected_attributes, num_epoch = 20):\n",
    "\n",
    "    # Create dictionaries to store results\n",
    "    selected_results_dict = {'accuracy': [], 'f1_score': []}\n",
    "    none_selected_results_dict = {'accuracy': [], 'f1_score': []}\n",
    "\n",
    "    # Setup the initial plot\n",
    "    plt.ion()  # Turn on interactive mode\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    \n",
    "    # Display the initial plot\n",
    "    def display_plot():\n",
    "        plt.tight_layout()\n",
    "        clear_output(wait=True)\n",
    "        display(fig)\n",
    "        plt.pause(0.1)  # Pause to allow the plot to update    \n",
    "        \n",
    "    # Initialize the TrainerHub class with the training configuration, data configuration, device, and use_print and use_wandb flags\n",
    "    trainer_hub = TrainerHub(ml_params, data_config, device, use_print = True, print_interval=200)\n",
    "    encoding_size = data_config.explain_size\n",
    "    \n",
    "    causal_model_dataset = CausalModelDataset(trainset, causal_model_selected_attributes)\n",
    "\n",
    "    for epoch in range(0, num_epoch):\n",
    "        selected_classifier = AttributeClassifier(encoding_size, num_classes).to(device)\n",
    "        none_selected_classifier = AttributeClassifier(encoding_size, num_classes).to(device)\n",
    "\n",
    "        print(f\"Training causal model at epoch {epoch}...\")\n",
    "        trainer_hub.train(causal_model_dataset)\n",
    "        causal_model = trainer_hub.ccnet\n",
    "        \n",
    "        # Train and evaluate classifiers on the explanation datasets\n",
    "        print(\"Training causal classifier on selected attributes...\")\n",
    "        trainset_selected_attributes = EncodingDataset(trainset, causal_model_selected_attributes, causal_model)\n",
    "        testset_selected_attributes = EncodingDataset(testset, causal_model_selected_attributes, causal_model)\n",
    "        \n",
    "        num_epoch_for_classifier = 1 if epoch != num_epoch - 1 else num_epoch\n",
    "        train_classifier(selected_classifier, trainset_selected_attributes, num_epochs=num_epoch_for_classifier)\n",
    "\n",
    "        print(\"Training classifier on none selected attributes...\")\n",
    "        trainset_none_selected_attributes = EncodingDataset(trainset, causal_model_none_selected_attributes, causal_model)\n",
    "        testset_none_selected_attributes = EncodingDataset(testset, causal_model_none_selected_attributes, causal_model)    \n",
    "        train_classifier(none_selected_classifier, trainset_none_selected_attributes, num_epochs=num_epoch_for_classifier)\n",
    "\n",
    "        # Test classifiers\n",
    "        test_classifiers(epoch, axs, \n",
    "                         selected_classifier, none_selected_classifier, \n",
    "                         testset_selected_attributes, testset_none_selected_attributes, \n",
    "                         selected_results_dict, none_selected_results_dict)\n",
    "        display_plot()\n",
    "\n",
    "    plt.ioff()  # Turn off interactive mode\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_causal_model_and_classifiers(causal_model_selected_attributes = male_and_smiling_attributes, causal_model_none_selected_attributes = eyeglasses_and_young_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_causal_model_and_classifiers(causal_model_selected_attributes = eyeglasses_and_young_attributes, causal_model_none_selected_attributes = male_and_smiling_attributes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
