{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:\n",
    "        \n",
    "        PARK, JunHo, junho@ccnets.org\n",
    "\n",
    "        \n",
    "        KIM, JeongYoong, jeongyoong@ccnets.org\n",
    "        \n",
    "    COPYRIGHT (c) 2024. CCNets. All Rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "path_append = \"../\" # Go up one directory from where you are.\n",
    "sys.path.append(path_append) \n",
    "\n",
    "from nn.utils.init import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "from torchvision import transforms\n",
    "\n",
    "# import albumentations\n",
    "n_img_sz = 64\n",
    "# Load the CelebA dataset for training. Specify the root directory where the dataset is located\n",
    "trainset = dset.CelebA(root=path_append + '../data/celeba', split = \"train\", transform=transforms.Compose([\n",
    "                            transforms.Resize(n_img_sz), # Transformations include resizing the images to `n_img_sz`\n",
    "                            transforms.CenterCrop(n_img_sz), # Center cropping to the same size\n",
    "                            transforms.ToTensor(), # Converting the images to tensors,\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalizing the pixel values to have a mean and standard deviation of 0.5 across all channels.\n",
    "                        ]), download= True)\n",
    "\n",
    "testset = dset.CelebA(root=path_append + '../data/celeba', split = \"test\", transform=transforms.Compose([\n",
    "                            transforms.Resize(n_img_sz), # Transformations include resizing the images to `n_img_sz`\n",
    "                            transforms.CenterCrop(n_img_sz), # Center cropping to the same size\n",
    "                            transforms.ToTensor(), # Converting the images to tensors\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalizing the pixel values to have a mean and standard deviation of 0.5 across all channels.\n",
    "                        ]), download= True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', \n",
    "              'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', \n",
    "              'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard', \n",
    "              'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', \n",
    "              'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young' ]\n",
    "\n",
    "causal_learning_selected_attributes = torch.tensor([label_list.index('Male')])\n",
    "causal_learning_none_selected_attributes = torch.tensor([label_list.index('Smiling')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for CelebA dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CausalModelDataset(Dataset):\n",
    "    def __init__(self, dataset, selected_attributes):\n",
    "        self.dataset = dataset\n",
    "        self.selected_attributes = selected_attributes\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.dataset[index]\n",
    "        y = torch.index_select(y.unsqueeze(0), 1, self.selected_attributes).squeeze(0)\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "class EncodingDataset(Dataset):\n",
    "    def __init__(self, dataset, attributes, causal_model):\n",
    "        self.dataset = dataset\n",
    "        self.attributes = attributes\n",
    "        self.causal_model = causal_model\n",
    "\n",
    "        data_loader = DataLoader(dataset=dataset, batch_size=256, shuffle=False, drop_last=False)\n",
    "        list_encodings = []\n",
    "        list_labels = []\n",
    "        with torch.no_grad():\n",
    "            for images, labels in data_loader:\n",
    "                images = images.to(self.causal_model.device)\n",
    "                encodings = self.causal_model.explain(images).detach().cpu()\n",
    "                attributes = labels[:, self.attributes]\n",
    "                list_encodings.append(encodings)\n",
    "                list_labels.append(attributes)\n",
    "        self.encodings = torch.cat(list_encodings, dim=0)\n",
    "        self.labels = torch.cat(list_labels, dim=0)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.encodings[index], self.labels[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer Name: causal_trainer\n",
      "\n",
      "\n",
      "\u001b[1mModelParameters Parameters:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccnet_config</th>\n",
       "      <th>ccnet_network</th>\n",
       "      <th>encoder_config</th>\n",
       "      <th>encoder_network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>See details below</td>\n",
       "      <td>resnet</td>\n",
       "      <td>None</td>\n",
       "      <td>none</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ccnet_config ccnet_network encoder_config encoder_network\n",
       "0  See details below        resnet           None            none"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[3m\n",
      "Detailed ccnet_config Configuration:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ccnet_config_model_name</th>\n",
       "      <th>ccnet_config_num_layers</th>\n",
       "      <th>ccnet_config_d_model</th>\n",
       "      <th>ccnet_config_dropout</th>\n",
       "      <th>ccnet_config_obs_shape</th>\n",
       "      <th>ccnet_config_condition_dim</th>\n",
       "      <th>ccnet_config_z_dim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>resnet</td>\n",
       "      <td>4</td>\n",
       "      <td>256</td>\n",
       "      <td>0.05</td>\n",
       "      <td>[3, 64, 64]</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ccnet_config_model_name  ccnet_config_num_layers  ccnet_config_d_model   \n",
       "0                  resnet                        4                   256  \\\n",
       "\n",
       "   ccnet_config_dropout ccnet_config_obs_shape  ccnet_config_condition_dim   \n",
       "0                  0.05            [3, 64, 64]                           2  \\\n",
       "\n",
       "   ccnet_config_z_dim  \n",
       "0                 128  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrainingParameters Parameters:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch_size</th>\n",
       "      <th>max_iters</th>\n",
       "      <th>max_seq_len</th>\n",
       "      <th>min_seq_len</th>\n",
       "      <th>num_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64</td>\n",
       "      <td>100000</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   batch_size  max_iters max_seq_len min_seq_len  num_epoch\n",
       "0          64     100000        None        None          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mOptimizationParameters Parameters:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clip_grad_range</th>\n",
       "      <th>decay_rate_100k</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>max_grad_norm</th>\n",
       "      <th>scheduler_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clip_grad_range  decay_rate_100k  learning_rate  max_grad_norm   \n",
       "0            None             0.05         0.0002            1.0  \\\n",
       "\n",
       "  scheduler_type  \n",
       "0    exponential  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mAlgorithmParameters Parameters:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enable_diffusion</th>\n",
       "      <th>error_function</th>\n",
       "      <th>reset_pretrained</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>mse</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   enable_diffusion error_function  reset_pretrained\n",
       "0             False            mse              True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataConfig Parameters:\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_name</th>\n",
       "      <th>task_type</th>\n",
       "      <th>obs_shape</th>\n",
       "      <th>label_size</th>\n",
       "      <th>explain_size</th>\n",
       "      <th>explain_layer</th>\n",
       "      <th>state_size</th>\n",
       "      <th>show_image_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>celeba</td>\n",
       "      <td>binary_classification</td>\n",
       "      <td>[3, 64, 64]</td>\n",
       "      <td>1</td>\n",
       "      <td>128</td>\n",
       "      <td>tanh</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  dataset_name              task_type    obs_shape  label_size  explain_size   \n",
       "0       celeba  binary_classification  [3, 64, 64]           1           128  \\\n",
       "\n",
       "  explain_layer state_size show_image_indices  \n",
       "0          tanh       None               None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tools.setting.ml_params import MLParameters\n",
    "from tools.setting.data_config import DataConfig\n",
    "from trainer_hub import TrainerHub\n",
    "num_classes = 1\n",
    "data_config = DataConfig(dataset_name = 'celebA', task_type='binary_classification', obs_shape=[3, n_img_sz, n_img_sz], \\\n",
    "                        label_size=num_classes)\n",
    "\n",
    "#  Set training configuration from the AlgorithmConfig class, returning them as a Namespace object.\n",
    "ml_params = MLParameters(ccnet_network = 'resnet')\n",
    "\n",
    "ml_params.training.num_epoch = 1\n",
    "ml_params.model.ccnet_config.num_layers = 4\n",
    "ml_params.algorithm.reset_pretrained = True\n",
    "\n",
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the TrainerHub class with the training configuration, data configuration, device, and use_print and use_wandb flags\n",
    "trainer_hub = TrainerHub(ml_params, data_config, device, use_print = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_model_dataset = CausalModelDataset(trainset, causal_learning_selected_attributes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers=4, hidden_size=128):\n",
    "        super(AttributeClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Create a list to hold all layers\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(input_size, hidden_size))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        # Register all layers\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train classifier\n",
    "decay_rate = 0.01\n",
    "iteration_100k = 100000\n",
    "gamma = pow(decay_rate, 1 / iteration_100k)    \n",
    "def train_classifier(model, optimizer, trainset):\n",
    "    model.train()\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=gamma)\n",
    "    train_loader = DataLoader(trainset, batch_size=64, shuffle=True)    \n",
    "    for data, labels in train_loader:\n",
    "        data, labels = data.to(device), labels.to(device).float()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "    # print learning rate\n",
    "    print(optimizer.param_groups[0]['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate classifier\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def test_classifier(model, dataset):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device).float()\n",
    "            outputs = model(data)\n",
    "            preds = torch.sigmoid(outputs).round()\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    print(confusion_matrix(all_labels, all_preds))\n",
    "    return accuracy, classification_report(all_labels, all_preds), confusion_matrix(all_labels, all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to store results\n",
    "def store_results(results_dict, epoch, causal_classifier, none_selected_classifier, testset_with_selected_attributes, testset_with_none_selected_attributes):\n",
    "    print(f\"Testing causal classifier on selected attributes at epoch {epoch}...\")\n",
    "    results_dict['selected'][epoch] = test_classifier(causal_classifier, testset_with_selected_attributes)\n",
    "    \n",
    "    print(f\"Testing classifier on none selected attributes at epoch {epoch}...\")\n",
    "    results_dict['none_selected'][epoch] = test_classifier(none_selected_classifier, testset_with_none_selected_attributes)\n",
    "\n",
    "# Create dictionaries to store results\n",
    "results_dict = {'selected': {}, 'none_selected': {}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training causal model at epoch 0...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d7cdcbfe8e54d87b8df6d7f3f086ad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15ab128f5e5b4fda8f39b6a7af9ca8dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/2543 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1][100/2543][Time 13.10]\n",
      "Unified LR across all optimizers: 0.0001993957766378747\n",
      "--------------------Training Metrics--------------------\n",
      "CCNet:  Three Resnet\n",
      "Inf: 0.1169\tGen: 0.4579\tRec: 0.4546\tE: 0.0248\tR: 0.0227\tP: 0.6780\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "encoding_size = data_config.explain_size\n",
    "causal_model = trainer_hub.ccnet\n",
    "\n",
    "selected_classifier = AttributeClassifier(encoding_size, num_classes).to(device)\n",
    "none_selected_classifier = AttributeClassifier(encoding_size, num_classes).to(device)\n",
    "selected_optimizer = torch.optim.Adam(selected_classifier.parameters(), lr=0.001)\n",
    "none_selected_optimizer = torch.optim.Adam(none_selected_classifier.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    print(f\"Training causal model at epoch {epoch}...\")\n",
    "    trainer_hub.train(causal_model_dataset)\n",
    "    \n",
    "    # Train and evaluate classifiers on the explanation datasets\n",
    "    print(\"Training causal classifier on selected attributes...\")\n",
    "    trainset_selected_attributes = EncodingDataset(trainset, causal_learning_selected_attributes, causal_model)\n",
    "    testset_selected_attributes = EncodingDataset(testset, causal_learning_selected_attributes, causal_model)\n",
    "\n",
    "    train_classifier(selected_classifier, selected_optimizer, trainset_selected_attributes)\n",
    "\n",
    "    print(\"Training classifier on none selected attributes...\")\n",
    "    trainset_none_selected_attributes = EncodingDataset(trainset, causal_learning_none_selected_attributes, causal_model)\n",
    "    testset_none_selected_attributes = EncodingDataset(testset, causal_learning_none_selected_attributes, causal_model)    \n",
    "    \n",
    "    train_classifier(none_selected_classifier, none_selected_optimizer, trainset_none_selected_attributes)\n",
    "    \n",
    "    # Store and print results\n",
    "    store_results(results_dict, epoch, selected_classifier, none_selected_classifier, testset_selected_attributes, testset_none_selected_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At the end, print all stored results if needed\n",
    "for key in results_dict:\n",
    "    print(f\"Results for {key}:\")\n",
    "    for epoch, result in results_dict[key].items():\n",
    "        print(f\"Epoch {epoch}:\")\n",
    "        print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
