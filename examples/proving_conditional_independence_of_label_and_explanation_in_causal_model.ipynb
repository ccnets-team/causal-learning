{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:\n",
    "        \n",
    "        PARK, JunHo, junho@ccnets.org\n",
    "\n",
    "        \n",
    "        KIM, JeongYoong, jeongyoong@ccnets.org\n",
    "        \n",
    "    COPYRIGHT (c) 2024. CCNets. All Rights reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "path_append = \"../\" # Go up one directory from where you are.\n",
    "sys.path.append(path_append) \n",
    "\n",
    "from nn.utils.init import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dset\n",
    "from torchvision import transforms\n",
    "\n",
    "# import albumentations\n",
    "n_img_sz = 128\n",
    "# Load the CelebA dataset for training. Specify the root directory where the dataset is located\n",
    "trainset = dset.CelebA(root=path_append + '../data/celeba', split = \"train\", transform=transforms.Compose([\n",
    "                            transforms.Resize(n_img_sz), # Transformations include resizing the images to `n_img_sz`\n",
    "                            transforms.CenterCrop(n_img_sz), # Center cropping to the same size\n",
    "                            transforms.ToTensor(), # Converting the images to tensors,\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalizing the pixel values to have a mean and standard deviation of 0.5 across all channels.\n",
    "                        ]), download= True)\n",
    "\n",
    "testset = dset.CelebA(root=path_append + '../data/celeba', split = \"test\", transform=transforms.Compose([\n",
    "                            transforms.Resize(n_img_sz), # Transformations include resizing the images to `n_img_sz`\n",
    "                            transforms.CenterCrop(n_img_sz), # Center cropping to the same size\n",
    "                            transforms.ToTensor(), # Converting the images to tensors\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalizing the pixel values to have a mean and standard deviation of 0.5 across all channels.\n",
    "                        ]), download= True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', \n",
    "              'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', \n",
    "              'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard', \n",
    "              'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', \n",
    "              'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young' ]\n",
    "\n",
    "causal_learning_selected_attributes = torch.tensor([label_list.index('Male')])\n",
    "causal_learning_none_selected_attributes = torch.tensor([label_list.index('Eyeglasses')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for CelebA dataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class CausalModelDataset(Dataset):\n",
    "    def __init__(self, dataset, selected_attributes):\n",
    "        self.dataset = dataset\n",
    "        self.selected_attributes = selected_attributes\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.dataset[index]\n",
    "        y = torch.index_select(y.unsqueeze(0), 1, self.selected_attributes).squeeze(0)\n",
    "        return X, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "class EncodingDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.encodings[index], self.labels[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_model_dataset = CausalModelDataset(trainset, causal_learning_selected_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.setting.ml_params import MLParameters\n",
    "from tools.setting.data_config import DataConfig\n",
    "from trainer_hub import TrainerHub\n",
    "num_classes = 1\n",
    "data_config = DataConfig(dataset_name = 'celebA', task_type='binary_classification', obs_shape=[3, n_img_sz, n_img_sz], \\\n",
    "                        label_size=num_classes, show_image_indices=[737, 1518, 390, 607])\n",
    "\n",
    "#  Set training configuration from the AlgorithmConfig class, returning them as a Namespace object.\n",
    "ml_params = MLParameters(ccnet_network = 'resnet')\n",
    "\n",
    "ml_params.training.num_epoch = 1\n",
    "ml_params.algorithm.reset_pretrained = True\n",
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the TrainerHub class with the training configuration, data configuration, device, and use_print and use_wandb flags\n",
    "trainer_hub = TrainerHub(ml_params, data_config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_hub.train(causal_model_dataset)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def generate_encoding_dataset(dataset, selected_attribute, none_selected_attribute):\n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=256, shuffle=False, drop_last=False)\n",
    "\n",
    "    encoding_tensor = None\n",
    "    selected_attribute_tensor = None\n",
    "    none_selected_attribute_tensor = None\n",
    "    is_first = True\n",
    "    causal_model = trainer_hub.ccnet\n",
    "\n",
    "    for batch_idx, (images, attributes) in enumerate(data_loader):\n",
    "        images = images.to(device)\n",
    "        attributes = attributes.to(device)\n",
    "        encoding = causal_model.explain(images)\n",
    "        \n",
    "        if is_first:\n",
    "            is_first = False\n",
    "            encoding_tensor = encoding\n",
    "            selected_attribute_tensor = attributes[:, selected_attribute]\n",
    "            none_selected_attribute_tensor = attributes[:, none_selected_attribute]\n",
    "        else:\n",
    "            encoding_tensor = torch.cat((encoding_tensor, encoding), dim=0)\n",
    "            selected_attribute_tensor = torch.cat((selected_attribute_tensor, attributes[:, selected_attribute]), dim=0)\n",
    "            none_selected_attribute_tensor = torch.cat((none_selected_attribute_tensor, attributes[:, none_selected_attribute]), dim=0)\n",
    "\n",
    "    encoding_tensor = encoding_tensor.clone().detach().cpu()\n",
    "    selected_attribute_tensor = selected_attribute_tensor.clone().detach().cpu()\n",
    "    none_selected_attribute_tensor = none_selected_attribute_tensor.clone().detach().cpu()\n",
    "    selected_attribute_dataset = EncodingDataset(encoding_tensor, selected_attribute_tensor)\n",
    "    none_selected_attribute_dataset = EncodingDataset(encoding_tensor, none_selected_attribute_tensor)\n",
    "\n",
    "    return selected_attribute_dataset, none_selected_attribute_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_with_selected_attributes, trainset_none_selected_attributes = generate_encoding_dataset(trainset, causal_learning_selected_attributes, causal_learning_none_selected_attributes)\n",
    "\n",
    "# Optional: DataLoader for the created datasets\n",
    "train_loader_with_selected_attributes = DataLoader(trainset_with_selected_attributes, batch_size=64, shuffle=True)\n",
    "train_loader_with_none_selected_attributes = DataLoader(trainset_none_selected_attributes, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_with_selected_attributes, testset_with_none_selected_attributes = generate_encoding_dataset(trainset, causal_learning_selected_attributes, causal_learning_none_selected_attributes)\n",
    "\n",
    "# Optional: DataLoader for the created datasets\n",
    "test_loader_with_selected_attributes = DataLoader(testset_with_selected_attributes, batch_size=64, shuffle=True)\n",
    "test_loader_with_none_selected_attributes = DataLoader(testset_with_none_selected_attributes, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttributeClassifier(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers=4, hidden_size=256):\n",
    "        super(AttributeClassifier, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Create a list to hold all layers\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(input_size, hidden_size))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        # Register all layers\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return torch.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train classifier\n",
    "def train_classifier(model, train_loader, num_epoch=5):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        model.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'\\nEpoch {epoch + 1} / {num_epoch}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate classifier\n",
    "import torch\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def test_classifier(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device).float()\n",
    "            outputs = model(data)\n",
    "            preds = torch.sigmoid(outputs).round()\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "    print(confusion_matrix(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate classifiers on the explanation datasets\n",
    "encoding_size = test_loader_with_selected_attributes.dataset.encodings.shape[-1]   \n",
    "causal_classifier = AttributeClassifier(encoding_size, num_classes).to(device)\n",
    "none_selected_classifier = AttributeClassifier(encoding_size, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training causal classifier on selected attributes...\")\n",
    "train_classifier(causal_classifier, train_loader_with_selected_attributes, num_epoch=5)\n",
    "\n",
    "print(\"Training classifier on none selected attributes...\")\n",
    "train_classifier(none_selected_classifier, train_loader_with_none_selected_attributes, num_epoch=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Testing causal classifier on selected attributes...\")\n",
    "test_classifier(causal_classifier, test_loader_with_selected_attributes)\n",
    "\n",
    "print(\"Testing classifier on none selected attributes...\")\n",
    "test_classifier(none_selected_classifier, test_loader_with_none_selected_attributes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
