{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "path_append = \"../\" # Go up one directory from where you are.\n",
    "sys.path.append(path_append) \n",
    "\n",
    "from tools.setting.ml_params import MLParameters\n",
    "from tools.setting.data_config import DataConfig\n",
    "from nn.utils.init import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dset\n",
    "from torchvision import transforms\n",
    "# import albumentations\n",
    "n_img_sz = 128\n",
    "attribute_indices = torch.tensor([20, 31]) # Male, Smiling\n",
    "\n",
    "# Load the CelebA dataset for training. Specify the root directory where the dataset is located\n",
    "trainset = dset.CelebA(root=path_append + '../data/celeba', split = \"train\", transform=transforms.Compose([\n",
    "                            transforms.Resize(n_img_sz), # Transformations include resizing the images to `n_img_sz`\n",
    "                            transforms.CenterCrop(n_img_sz), # Center cropping to the same size\n",
    "                            transforms.ToTensor(), # Converting the images to tensors,\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalizing the pixel values to have a mean and standard deviation of 0.5 across all channels.\n",
    "                        ]), download= False)\n",
    "\n",
    "testset = dset.CelebA(root=path_append + '../data/celeba', split = \"test\", transform=transforms.Compose([\n",
    "                            transforms.Resize(n_img_sz), # Transformations include resizing the images to `n_img_sz`\n",
    "                            transforms.CenterCrop(n_img_sz), # Center cropping to the same size\n",
    "                            transforms.ToTensor(), # Converting the images to tensors\n",
    "                            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # Normalizing the pixel values to have a mean and standard deviation of 0.5 across all channels.\n",
    "                        ]), download= False)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom dataset class for CelebA dataset\n",
    "class CelebA(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.dataset[index] # Get the image and label at the specified index\n",
    "        y= torch.index_select(y.unsqueeze(0), 1, attribute_indices).squeeze(0) # Select specific attributes(Male, Smiling) for the label using a predefined list of indices\n",
    "        return X, y # Return the image and the selected attri   butes\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset) # Return the size of the dataset\n",
    "        \n",
    "trainset = CelebA(trainset)\n",
    "testset = CelebA(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(dataset_name = 'celebA', task_type='multi_label_classification', obs_shape=[3, 128, 128], label_size=2, \\\n",
    "                        show_image_indices=[737, 1518, 390, 607])\n",
    "\n",
    "#  Set training configuration from the AlgorithmConfig class, returning them as a Namespace object.\n",
    "ml_params = MLParameters(ccnet_network = 'resnet', encoder_network = 'none')\n",
    "ml_params.model.ccnet_config.d_model = 256\n",
    "ml_params.model.ccnet_config.d_model = 512\n",
    "ml_params.training.num_epoch = 1\n",
    "\n",
    "first_data = trainset[0]\n",
    "X, y = first_data\n",
    "\n",
    "print(f\"Input shape: {X.shape}\")\n",
    "print(f\"Label shape: {y.shape}\")\n",
    "\n",
    "print(f\"Total number of samples in trainset: {len(trainset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trainer_hub import TrainerHub\n",
    "\n",
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Initialize the TrainerHub class with the training configuration, data configuration, device, and use_print and use_wandb flags\n",
    "trainer_hub = TrainerHub(ml_params, data_config, device, use_print=True, use_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_hub.train(trainset, testset)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = ['5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', \n",
    "              'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', \n",
    "              'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard', \n",
    "              'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', \n",
    "              'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young' ]\n",
    "\n",
    "original_labels = torch.tensor([20, 31]) # Male, Smiling\n",
    "selected_labels = torch.tensor([label_list.index('Bald'), label_list.index('Eyeglasses')]) # Bald, Eyeglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "class ExtendedCelebA(Dataset):\n",
    "    def __init__(self, dataset, attributes_path, extra_attrs_indices):\n",
    "        self.dataset = dataset\n",
    "        self.attrs = pd.read_csv(attributes_path, delim_whitespace=True, header=1)\n",
    "        # display(self.attrs.head())\n",
    "        self.extra_attrs_indices = extra_attrs_indices\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        X, y = self.dataset[index]\n",
    "        img_name = self.dataset.dataset.filename[index]\n",
    "        extra_attrs = self.attrs.loc[img_name].iloc[self.extra_attrs_indices].values\n",
    "        extra_attrs = (extra_attrs + 1) // 2  # Convert -1, 1 to 0, 1\n",
    "        extra_attrs = torch.tensor(extra_attrs, dtype=torch.float32)\n",
    "        y = torch.cat((y, extra_attrs))\n",
    "\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "\n",
    "extra_attrs_indices = torch.tensor([label_list.index('Bald'), label_list.index('Eyeglasses')]) # Bald, Eyeglasses\n",
    "\n",
    "\n",
    "extended_trainset = ExtendedCelebA(testset, path_append + '../data/celeba/celeba/list_attr_celeba.txt', extra_attrs_indices)\n",
    "extended_testset = ExtendedCelebA(testset, path_append + '../data/celeba/celeba/list_attr_celeba.txt', extra_attrs_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in extended_testset:\n",
    "    print(images.shape, labels.shape)  \n",
    "    break  # check only the first sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=extended_testset, batch_size=64, shuffle=False, drop_last=False)\n",
    "\n",
    "ccnet = trainer_hub.ccnet\n",
    "explanation = None\n",
    "\n",
    "explanation_dataset = []\n",
    "original_labels_gender_dataset = []\n",
    "original_labels_smile_dataset = []\n",
    "extra_labels_bald_dataset = []\n",
    "extra_labels_glasses_dataset = []\n",
    "\n",
    "\n",
    "for data, labels in tqdm.tqdm(test_loader):\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    original_labels_gender = labels[:, 0]  # Gender \n",
    "    original_labels_smile = labels[:, 1]   # Smile \n",
    "    extra_labels_bald = labels[:, 2]       # Bald \n",
    "    extra_labels_glasses = labels[:, 3]    # Glasses \n",
    "    \n",
    "    # Use CCNet to explain the original data and generate synthetic counterparts\n",
    "    explanations = ccnet.explain(data)\n",
    "    \n",
    "    # append to the list\n",
    "    explanation_dataset.append(explanations.detach())\n",
    "    \n",
    "    original_labels_gender_dataset.append(original_labels_gender.detach())\n",
    "    original_labels_smile_dataset.append(original_labels_smile.detach())\n",
    "    \n",
    "    extra_labels_bald_dataset.append(extra_labels_bald.detach())\n",
    "    extra_labels_glasses_dataset.append(extra_labels_glasses.detach())\n",
    "\n",
    "# transform to tensor\n",
    "explanation_tensor = torch.cat(explanation_dataset, dim=0)\n",
    "\n",
    "original_labels_gender_tensor = torch.cat(original_labels_gender_dataset, dim=0)\n",
    "original_labels_smile_tensor = torch.cat(original_labels_smile_dataset, dim=0)\n",
    "\n",
    "extra_labels_bald_tensor = torch.cat(extra_labels_bald_dataset, dim=0)\n",
    "extra_labels_glasses_tensor = torch.cat(extra_labels_glasses_dataset, dim=0)\n",
    "\n",
    "# generate dataset\n",
    "dataset_with_gender_labels = TensorDataset(explanation_tensor, original_labels_gender_tensor)\n",
    "dataset_with_smile_labels = TensorDataset(explanation_tensor, original_labels_smile_tensor)\n",
    "\n",
    "dataset_with_bald_labels = TensorDataset(explanation_tensor, extra_labels_bald_tensor)\n",
    "dataset_with_glasses_labels = TensorDataset(explanation_tensor, extra_labels_glasses_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Assuming each explanation has a size of 128*128 for example purposes\n",
    "input_size = 256  # This should be adjusted based on your actual data size\n",
    "num_classes = 1  # Binary classification\n",
    "\n",
    "def train_supervised_model(model, dataset, num_epoch=5, device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True, )\n",
    "\n",
    "    for epoch in tqdm.tqdm(range(num_epoch)):\n",
    "        model.train()\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "            loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, labels.unsqueeze(1).float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # metrics\n",
    "    print(f'\\nEpoch {epoch + 1} / {num_epoch}')\n",
    "    evaluate_model(model, train_loader, device)\n",
    "\n",
    "def evaluate_model(model, data_loader, device):\n",
    "    model.eval()  \n",
    "    predictions = []\n",
    "    ground_truth = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, labels in data_loader:\n",
    "            data, labels = data.to(device), labels.to(device, dtype=torch.float32)\n",
    "            outputs = model(data)\n",
    "            \n",
    "   \n",
    "            # if output shape is [batch_size, 1], then squeeze the last dimension\n",
    "            if outputs.ndim == 2 and outputs.shape[1] == 1:\n",
    "                predicted = outputs.squeeze().round()  # predict result by rounding the probability\n",
    "            else:\n",
    "                predicted = outputs.round()  \n",
    "            \n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            ground_truth.extend(labels.view(-1).cpu().numpy())\n",
    "    \n",
    "    accuracy = accuracy_score(ground_truth, predictions)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = LogisticRegressionModel(input_size, num_classes).to(device)\n",
    "\n",
    "# Assuming explanations are already flattened and prepared in dataset loaders\n",
    "print(\"Training with original labels:\")\n",
    "train_supervised_model(model, dataset_with_gender_labels)\n",
    "evaluate_model(model, dataset_with_gender_labels, device)\n",
    "print('='*20)\n",
    "\n",
    "print(\"Training with original labels:\")\n",
    "train_supervised_model(model, dataset_with_smile_labels)\n",
    "evaluate_model(model, dataset_with_smile_labels, device)\n",
    "print('='*20)\n",
    "\n",
    "print(\"Training with extra labels:\")\n",
    "train_supervised_model(model, dataset_with_bald_labels)\n",
    "evaluate_model(model, dataset_with_bald_labels, device)\n",
    "print('='*20)\n",
    "\n",
    "print(\"Training with extra labels:\")\n",
    "train_supervised_model(model, dataset_with_glasses_labels)\n",
    "evaluate_model(model, dataset_with_glasses_labels, device)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
