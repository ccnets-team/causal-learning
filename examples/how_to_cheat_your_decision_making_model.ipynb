{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:\n",
    "        \n",
    "        PARK, JunHo, junho@ccnets.org\n",
    "\n",
    "    COPYRIGHT (c) 2024. CCNets. All Rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheat Your Decision-Making Model: Manipulating Credit Card Data with Causal Inference\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial, we delve into the intricate world of causal inference to manipulate decision-making models in the domain of credit card fraud detection. Utilizing a Cooperative Network (CCNet), we explore how subtle manipulations in non-fraudulent data can expose and test the vulnerabilities of machine learning models. This demonstration not only highlights the robustness and weaknesses of current fraud detection systems but also illustrates the ethical considerations and potential risks inherent in data manipulation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Goals\n",
    "\n",
    "This tutorial provides a guide on using causal inference to manipulate data and evaluate its impact on machine learning models. We will cover:\n",
    "\n",
    "1. **Training a Binary Classifier**: Train a model to distinguish between fraudulent and non-fraudulent transactions using real credit card data.\n",
    "2. **Generating Manipulated Data with CCNet**: Use CCNet's Explainer, Reasoner, and Producer networks to create data that mimics non-fraudulent transactions but is designed to deceive the classifier by switching decision label factors.\n",
    "3. **Evaluating Classifier Performance**: Test the classifier on both original and manipulated datasets to assess robustness. The classifier should perform well on both the original test set and the CCNet-recreated test set, indicating that CCNet has learned the data distribution that the classifier mapped for decision making.\n",
    "4. **Comparative Dataset Analysis**:\n",
    "   - **Testset A**: Real Test Data - Authentic credit card transactions used as a baseline to evaluate the classifier's performance.\n",
    "   - **Testset B**: CCNet-generated data with random labels but maintaining the same frequency distribution as the original. The classifier's performance should be similar to Testset A, showing that CCNet understands the classifier's decision-making process.\n",
    "   - **Testset C**: CCNet-generated data with original labels. With Testset B, it is proved that CCNet creates the genuine data distribution for any case of decision label. However, as most information of the data is in the explanation vector, it is easy to manipulate by changing the decision factor of the fraud data. In short, it is easy to manipulate the decision-making process by causal inference.\n",
    "5. **Ethical Considerations**: Discuss the ethical implications of data manipulation in machine learning, emphasizing the need for robustness in model training and the risks of misuse in applications like fraud detection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path_append = \"../\"\n",
    "sys.path.append(path_append)  # Go up one directory from where you are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_7_DeepLearning/FeedForwardNeuralNetworks.html\n",
    "import pandas as pd \n",
    "\n",
    "dataroot = path_append + \"../data/credit_card_fraud_detection/creditcard.csv\"\n",
    "df = pd.read_csv(dataroot)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('No Frauds', round(df['Class'].value_counts()[0] / len(df) *100,2), '%of the dataset')\n",
    "print('Frauds', round(df['Class'].value_counts()[1] / len(df) *100,2), '%of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# Initialize scalers\n",
    "standard_sc = StandardScaler()\n",
    "robust_sc = RobustScaler()\n",
    "# Scale 'Amount' and 'Time' columns separately\n",
    "df['scaled_amount'] = robust_sc.fit_transform(df['Amount'].values.reshape(-1, 1))\n",
    "df['scaled_time'] = robust_sc.fit_transform(df['Time'].values.reshape(-1, 1))\n",
    "\n",
    "# Drop original 'Time' and 'Amount' columns\n",
    "df.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
    "\n",
    "# Move the 'Class' column to the end\n",
    "class_column = df.pop('Class')\n",
    "df = pd.concat([df, class_column], axis=1)\n",
    "\n",
    "# Scale the rest of the features (excluding the class column)\n",
    "df.iloc[:, :-1] = standard_sc.fit_transform(df.iloc[:, :-1])\n",
    "\n",
    "# Calculate the number of features and classes\n",
    "n_features = len(df.iloc[:, :-1].columns)\n",
    "n_classes = len(df.iloc[:, -1:].columns)\n",
    "\n",
    "print(n_features, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the labeled and unlabeled dataset classes\n",
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        vals = torch.tensor(self.x[index], dtype=torch.float32)\n",
    "        label = torch.tensor(self.y[index], dtype=torch.long)\n",
    "        return vals, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Splitting for Training and Testing\n",
    "\n",
    "The original dataset is split into training and testing parts to evaluate the model's performance accurately. This step is crucial for validating the effectiveness of the training on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and test sets for model evaluation\n",
    "df_train, df_test = train_test_split(df, test_size=0.5, shuffle=True, random_state=42)\n",
    "X_train, y_train = df_train.iloc[:, :-1].values, df_train.iloc[:, -1:].values\n",
    "X_test, y_test = df_test.iloc[:, :-1].values, df_test.iloc[:, -1:].values\n",
    "\n",
    "# Labeled datasets for supervised learning tasks\n",
    "trainset = LabeledDataset(X_train, y_train)  # Corrected to include training data\n",
    "testset = LabeledDataset(X_test, y_test)     # Test set with proper labels\n",
    "\n",
    "# Printing the shapes of the datasets for verification\n",
    "print(f\"Labeled Trainset Shape: {len(trainset)}, {trainset.x.shape[1]}\")\n",
    "print(f\"Labeled Testset Shape: {len(testset)}, {testset.x.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Setup and Model Configuration\n",
    "\n",
    "This section initializes the environment by setting a fixed random seed to ensure reproducibility of results. It imports necessary configurations and initializes model parameters with specific configurations. The model specified here is set to have no core model but uses a 'tabnet' encoder model for data processing, which is particularly tailored for structured or tabular data like credit card transactions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed random seed for reproducibility of experiments\n",
    "from nn.utils.init import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "# Importing configuration setups for ML parameters and data\n",
    "import torch\n",
    "from tools.setting.ml_params import MLParameters\n",
    "from tools.setting.data_config import DataConfig\n",
    "from trainer_hub import TrainerHub\n",
    "\n",
    "# Configuration for the data handling, defining dataset specifics and the task type\n",
    "data_config = DataConfig(dataset_name='CreditCardFraudDetection', task_type='binary_classification', obs_shape=[n_features], label_size=n_classes, explain_size=n_features - n_classes)\n",
    "\n",
    "# Initializing ML parameters without a core model and setting the encoder model to 'tabnet' with specific configurations\n",
    "ml_params = MLParameters(core_model='tabnet', encoder_model='none')\n",
    "\n",
    "# Setting training parameters and device configuration\n",
    "ml_params.training.num_epoch = 10\n",
    "ml_params.model.core_config.num_layers = 3\n",
    "ml_params.algorithm.error_function = 'mse'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Create a TrainerHub instance to manage training and data processing\n",
    "trainer_hub = TrainerHub(ml_params, data_config, device, use_print=True, use_wandb=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_model = False\n",
    "if load_model:\n",
    "    trainer_hub.load_trainer(core_model = True)\n",
    "else:\n",
    "    trainer_hub.train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader for processing training data in larger batches without shuffling\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=256, shuffle=False, drop_last=False)\n",
    "\n",
    "# CCNet setup for generating synthetic manipulated data\n",
    "ccnet = trainer_hub.core_ccnet\n",
    "manipulated_data = None\n",
    "random_labels = None\n",
    "original_labels = None\n",
    "probability_positive = 0.0017 # 0.17% of the data is positive\n",
    "\n",
    "# Generate synthetic data to enhance the diversity of the training dataset\n",
    "for data, labels in test_loader:\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Create random labels with 0.17% positive (1) and 99.83% negative (0) labels\n",
    "    random_label = (torch.rand(labels.size(0)).to(device) < probability_positive).float()\n",
    "    random_label = torch.nn.functional.one_hot(random_label.to(torch.int64), num_classes=2).float()\n",
    "\n",
    "    # Use CCNet to explain the original data and generate synthetic counterparts\n",
    "    explanations = ccnet.explain(data)\n",
    "    synthetic_data = ccnet.produce(random_label, explanations)\n",
    "    \n",
    "    # Detach synthetic data and labels from GPU for further processing\n",
    "    synthetic_data = synthetic_data.detach().cpu()\n",
    "    random_label = random_label.detach().cpu().argmax(dim=-1).unsqueeze(-1)\n",
    "    labels = labels.detach().cpu()\n",
    "\n",
    "    # Accumulate the generated data for analysis and training\n",
    "    if manipulated_data is None:\n",
    "        manipulated_data = synthetic_data\n",
    "        random_labels = random_label\n",
    "        original_labels = labels\n",
    "    else:\n",
    "        manipulated_data = torch.cat([manipulated_data, synthetic_data], dim=0)\n",
    "        random_labels = torch.cat([random_labels, random_label], dim=0)\n",
    "        original_labels = torch.cat([original_labels, labels], dim=0)\n",
    "\n",
    "# Output the shapes of the datasets for verification\n",
    "print(f\"Manipulated Data Shape: {manipulated_data.shape}\")\n",
    "print(f\"Reversed Labels Shape: {random_labels.shape}\")\n",
    "print(f\"Original Labels Shape: {original_labels.shape}\")\n",
    "\n",
    "# Create datasets for both synthetic and original label scenarios\n",
    "random_label_testset = LabeledDataset(manipulated_data.numpy(), random_labels.numpy())\n",
    "original_label_testset = LabeledDataset(manipulated_data.numpy(), original_labels.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Supervised Models\n",
    "\n",
    "This section outlines the process of training supervised learning models using both original and synthetic datasets. The `train_supervised_model` function is designed to iterate through the dataset, perform forward passes, compute loss, and update model weights using backpropagation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised_model(model, dataset, num_epoch=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    # Initialize the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # Ensure reproducibility by resetting the random seed\n",
    "    # Create DataLoader for batch processing\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    # Training loop\n",
    "    for epoch in range(num_epoch):  # Train for 2 epochs as an example\n",
    "        for i, (data, label) in enumerate(trainloader):\n",
    "            data = data.to(device).clone().detach()\n",
    "            label = label.to(device).float()\n",
    "            # Perform forward pass\n",
    "            output = model(data)\n",
    "            # Compute loss\n",
    "            loss = torch.nn.functional.binary_cross_entropy(output, label)\n",
    "            # Backward pass to compute gradients\n",
    "            loss.backward()\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers=4, hidden_size=256):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Create a list to hold all layers\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(input_size, hidden_size))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        # Register all layers\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "# Initialize and train a model on the recreated dataset\n",
    "decision_making_model = MLP(input_size=n_features, output_size=n_classes).to(device)\n",
    "train_supervised_model(decision_making_model, trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def get_f1_score(model, input_testset, device, batch_size=64):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # DataLoader for testing\n",
    "    test_loader = torch.utils.data.DataLoader(input_testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # No gradient computation needed during inference\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(data)\n",
    "            # Process output for binary classification\n",
    "            predicted = (output.squeeze() > 0.5).long()\n",
    "            y_true.extend(label.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Compute and return the F1 score\n",
    "    score = f1_score(y_true, y_pred, average='binary')\n",
    "    return score\n",
    "\n",
    "# Calculate F1 scores for both models\n",
    "fraud_detection_f1_score = get_f1_score(decision_making_model, testset, device)\n",
    "random_testset_f1_score = get_f1_score(decision_making_model, random_label_testset, device)\n",
    "manipulated_testset_f1_score = get_f1_score(decision_making_model, original_label_testset, device)\n",
    "\n",
    "# Output the results\n",
    "print(\"F1 score of the supervised learning model tested on the original data: \", fraud_detection_f1_score)\n",
    "print(\"F1 score of the supervised learning model tested on the manipulated data with random label: \", random_testset_f1_score)\n",
    "print(\"F1 score of the supervised learning model tested on the manipulated data with original label: \", manipulated_testset_f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
