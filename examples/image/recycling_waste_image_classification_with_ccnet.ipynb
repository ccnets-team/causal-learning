{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Author:\n",
    "        \n",
    "        PARK, JunHo, junho@ccnets.org\n",
    "\n",
    "        \n",
    "        KIM, JoengYoong, jeongyoong@ccnets.org\n",
    "        \n",
    "    COPYRIGHT (c) 2024. CCNets. All Rights reserved.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recyclable and Household Waste Classification \n",
    "\n",
    "\n",
    "https://www.kaggle.com/datasets/alistairking/recyclable-and-household-waste-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "path_append = \"../../\" # Go up one directory from where you are.\n",
    "sys.path.append(path_append) \n",
    "\n",
    "from tools.setting.ml_params import MLParameters\n",
    "from tools.setting.data_config import DataConfig\n",
    "from nn.utils.init_layer import set_random_seed\n",
    "set_random_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = '../data/Recyclable and Household Waste Classification/images/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "def gather_and_split_data(root_dir, train_split=0.6, val_split=0.2, test_split=0.2):\n",
    "    classes = sorted(os.listdir(root_dir))\n",
    "    all_image_paths = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Gather all image paths and labels\n",
    "    for i, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        for subfolder in ['default', 'real_world']:\n",
    "            subfolder_dir = os.path.join(class_dir, subfolder)\n",
    "            image_names = os.listdir(subfolder_dir)\n",
    "            for image_name in image_names:\n",
    "                image_path = os.path.join(subfolder_dir, image_name)\n",
    "                all_image_paths.append(image_path)\n",
    "                all_labels.append(i)\n",
    "    \n",
    "    # Shuffle all images and labels in the same way\n",
    "    combined_list = list(zip(all_image_paths, all_labels))\n",
    "    random.shuffle(combined_list)\n",
    "    all_image_paths, all_labels = zip(*combined_list)\n",
    "\n",
    "    # Compute split indices\n",
    "    num_images = len(all_image_paths)\n",
    "    train_end = int(train_split * num_images)\n",
    "    val_end = train_end + int(val_split * num_images)\n",
    "    \n",
    "    # Split data\n",
    "    train_data = (all_image_paths[:train_end], all_labels[:train_end])\n",
    "    val_data = (all_image_paths[train_end:val_end], all_labels[train_end:val_end])\n",
    "    test_data = (all_image_paths[val_end:], all_labels[val_end:])\n",
    "    \n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "class WasteDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.image_paths[index]\n",
    "        label = self.labels[index]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        label = label.unsqueeze(-1)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 128, 128])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Create the datasets and data loaders\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Define your root directory and transformations\n",
    "root_dir = path_append + dataset_path\n",
    "\n",
    "# Gather and split data\n",
    "train_data, val_data, test_data = gather_and_split_data(root_dir)\n",
    "\n",
    "# Create dataset instances\n",
    "train_dataset = WasteDataset(*train_data, transform=transform)\n",
    "val_dataset = WasteDataset(*val_data, transform=transform)\n",
    "test_dataset = WasteDataset(*test_data, transform=transform)\n",
    "\n",
    "X, y = train_dataset[0]\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_config = DataConfig(dataset_name = 'recycle_image', task_type='multi_class_classification', obs_shape=[3, 128, 128], label_size=30)\n",
    "\n",
    "#  Set training configuration from the AlgorithmConfig class, returning them as a Namespace object.\n",
    "ml_params = MLParameters(model_name = 'resnet18')\n",
    "\n",
    "ml_params.optimization.learning_rate = 2e-4\n",
    "\n",
    "from causal_learning import CausalLearning\n",
    "\n",
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Initialize the CausalLearning class with the training configuration, data configuration, device, and use_print and use_wandb flags\n",
    "causal_learning = CausalLearning(ml_params, data_config, device, use_print=True, use_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Currently logged in as: junhopark. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\CCNets-team\\Projects\\causal-learning\\examples\\image\\wandb\\run-20240621_232221-v4fmnl9f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/junhopark/causal-learning/runs/v4fmnl9f' target=\"_blank\">recycle_image : 24-06-21 23:22:17</a></strong> to <a href='https://wandb.ai/junhopark/causal-learning' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/junhopark/causal-learning' target=\"_blank\">https://wandb.ai/junhopark/causal-learning</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/junhopark/causal-learning/runs/v4fmnl9f' target=\"_blank\">https://wandb.ai/junhopark/causal-learning/runs/v4fmnl9f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Adding directory to artifact (.\\..\\saved\\recycle_image\\causal-learning)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "359cf38f4253415aa8a297646dafbb1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72637097920648db8078e3e268dd6f42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/100][100/140][Time 29.42]\n",
      "Unified LR across all optimizers: 0.0001993957766378747\n",
      "=====================Train Metrics=======================\n",
      "CCNet:  Three Resnet18\n",
      "Inf: 0.0603\tGen: 0.5678\tRec: 0.5671\tE: 0.0081\tR: 0.0078\tP: 1.2247\n",
      "\n",
      "accuracy: 0.1250\n",
      "precision: 0.0265\n",
      "recall: 0.0915\n",
      "f1_score: 0.0359\n",
      "\n",
      "=====================Eval Metrics========================\n",
      "accuracy: 0.1133\n",
      "precision: 0.0223\n",
      "recall: 0.0970\n",
      "f1_score: 0.0346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "causal_learning.train(train_dataset, val_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
