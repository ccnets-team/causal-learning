{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:\n",
    "        \n",
    "        PARK, JunHo, junho@ccnets.org\n",
    "\n",
    "        \n",
    "        KIM, JeongYoong, jeongyoong@ccnets.org\n",
    "        \n",
    "    COPYRIGHT (c) 2024. CCNets. All Rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to CCNet: A New Paradigm in Causal Learning\n",
    "\n",
    "## Overview of CCNet\n",
    "CCNet (Cooperative Causal Network) introduces a framework for understanding causal dynamics in observed data, specifically decoupling the direct causes of an observation (X) from the target outcome (Y). This model employs neural networks to identify explanatory factors in observed data that are conditionally independent of the target variable given the observations.\n",
    "\n",
    "## A Method for Causal Learning with Neural Networks\n",
    "CCNet elucidates the causal relationship between observed data (X) and target outcomes (Y) using three interconnected neural network models: the Explainer, the Reasoner, and the Producer. This tutorial aims to demonstrate the conditional independence of explanatory factors (E) from the target outcome (Y) given the observation (X).\n",
    "\n",
    "## Experiment Description\n",
    "\n",
    "### Objective\n",
    "Empirically validate the conditional independence of explanatory factors (E) from the target outcome (Y) given the observations (X) using CCNet in the context of credit card fraud detection.\n",
    "\n",
    "### Dataset\n",
    "The experiment uses a credit card fraud detection dataset, comprising features related to transaction details and the target variable indicating fraud. Specifically:\n",
    "- `df_y_class`: The binary target indicating fraud status, used for binary classification.\n",
    "- `df_y_amount`: The continuous target indicating transaction amount, used for regression.\n",
    "\n",
    "This dataset serves as the basis for configuring the causal model dataset for training CCNet.\n",
    "\n",
    "### Methodology\n",
    "\n",
    "#### Dataset Preparation\n",
    "- **CausalModelDataset**: Configures the dataset to include specific features hypothesized to be causally related to the target outcomes. For fraud detection, this includes features relevant to transactions, with either `df_y_class` or `df_y_amount` as the target.\n",
    "- **EncodingDataset**: Generates encodings (explanatory factors) from the dataset using the causal model for classifier training.\n",
    "\n",
    "#### Training Process\n",
    "- **Causal Model Training**: Iteratively train the causal model over several epochs to refine the understanding of causal relationships between transaction features and the outcomes.\n",
    "- **Classifier Training and Evaluation**:\n",
    "  - **Selected Feature Classifier**: Trained on encodings of the selected features. In the context of this experiment, this would involve either the binary classification or regression task for fraud detection using `df_y_class` or `df_y_amount`.\n",
    "  - **Non-Selected Feature Classifier**: Trained on encodings of the non-selected features. Here, this would correspond to the regression task or binary classification using `df_y_amount` or `df_y_class`.\n",
    "  - The training process also switches selected and non-selected features, training the causal model with different combinations (e.g., using fraud status and then transaction amounts) to evaluate the classifier's ability to predict other features.\n",
    "\n",
    "#### Validation and Visualization\n",
    "- **Performance Metrics**: Record accuracy and F1 score for the binary classification task, and mean squared error (MSE) and mean absolute error (MAE) for the regression task. These metrics are used to compare the effectiveness of the causal model.\n",
    "- **Plotting Results**: Visualize performance trends over epochs to assess the impact of the causal model on classifier performance.\n",
    "\n",
    "### Summary\n",
    "\n",
    "The experiment aims to validate CCNet's proficiency in identifying and utilizing causal relationships in the credit card fraud detection dataset. By focusing on conditional independence and evaluating classifier performance across both binary classification (fraud detection using `df_y_class`) and regression (transaction amount prediction using `df_y_amount`), the experiment provides empirical evidence of CCNet's efficacy in causal generation. This highlights CCNet's ability to learn a generative graph that accurately captures the causal dynamics in fraudulent transactions.\n",
    "\n",
    "### Key Insights\n",
    "\n",
    "- **Target Versatility**: The experiment demonstrates the flexibility of CCNet in handling different types of target variables. Whether predicting fraud status (binary classification) or transaction amount (regression), the model adapts to learn the causal relationships effectively.\n",
    "- **Conditional Independence**: The analysis emphasizes proving that explanatory factors (E) are conditionally independent of the target outcome (Y) given observations (X), ensuring robust causal inference.\n",
    "- **Causal Generation**: The ability of CCNet to generate realistic transaction data based on learned causal relationships showcases its strength in modeling generative processes beyond simple prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd \n",
    "path_append = \"../\"\n",
    "sys.path.append(path_append)  # Go up one directory from where you are.\n",
    "\n",
    "# https://fraud-detection-handbook.github.io/fraud-detection-handbook/Chapter_7_DeepLearning/FeedForwardNeuralNetworks.html\n",
    "\n",
    "dataroot = path_append + \"../data/credit_card_fraud_detection/creditcard.csv\"\n",
    "df = pd.read_csv(dataroot)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('No Frauds', round(df['Class'].value_counts()[0] / len(df) *100,2), '%of the dataset')\n",
    "print('Frauds', round(df['Class'].value_counts()[1] / len(df) *100,2), '%of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from tools.preprocessing.data_frame import auto_preprocess_dataframe\n",
    "from tools.preprocessing.scaler import scale_dataframe\n",
    "\n",
    "target_columns = ['Amount', 'Class']\n",
    "df, description = auto_preprocess_dataframe(df, target_columns)\n",
    "df, scale_amount = scale_dataframe(df, transform_columns = ['Amount'])\n",
    "scale_class = None\n",
    "\n",
    "df_x = df.drop(columns = target_columns)\n",
    "df_y_class = df['Class']\n",
    "task_type_class = 'binary_classification'\n",
    "\n",
    "df_y_amount = df['Amount']\n",
    "task_type_amount = 'regression'\n",
    "\n",
    "X = torch.tensor(df_x.values[:], dtype=torch.float32)\n",
    "y_class = torch.tensor(df_y_class.values[:], dtype=torch.float32).unsqueeze(-1)\n",
    "y_amount = torch.tensor(df_y_amount.values[:], dtype=torch.float32).unsqueeze(-1)\n",
    "\n",
    "num_features = description['num_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the labeled and unlabeled dataset classes\n",
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        vals = self.x[index] if isinstance(self.x, torch.Tensor) else torch.tensor(self.x[index], dtype=torch.float32)\n",
    "        label = self.y[index] if isinstance(self.y, torch.Tensor) else torch.tensor(self.y[index], dtype=torch.float32)\n",
    "        return vals, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from nn.tabnet import TabNet \n",
    "from tools.setting.ml_params import ModelConfig\n",
    "\n",
    "class PredictionModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, task_type, num_layers=3, hidden_size=256):\n",
    "        super(PredictionModel, self).__init__()\n",
    "        \n",
    "        if task_type == 'binary_classification':\n",
    "            final_act = torch.nn.Sigmoid()\n",
    "        elif task_type == 'regression':\n",
    "            final_act = torch.nn.Identity()\n",
    "        \n",
    "        self.final_act = final_act\n",
    "        \n",
    "        model_config = ModelConfig('tabnet')\n",
    "        model_config.num_layers = num_layers\n",
    "        model_config.d_model = hidden_size\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Create a list to hold all layers\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(input_size, hidden_size))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        ## Add TabNet layers\n",
    "        layers.append(TabNet(model_config))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        # Register all layers\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return self.final_act(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Plotting Functions\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "\n",
    "def display_plot(fig):\n",
    "    plt.tight_layout()\n",
    "    clear_output(wait=True)\n",
    "    display(fig, display_id='fig')\n",
    "    plt.pause(0.1)  # Pause to allow the plot to update\n",
    "\n",
    "def update_annot(ind, line, annot):\n",
    "    pos = line.get_offsets()[ind[\"ind\"][0]]\n",
    "    annot.xy = pos\n",
    "    text = f\"{pos[0]:.2f}, {pos[1]:.2f}\"\n",
    "    annot.set_text(text)\n",
    "    annot.get_bbox_patch().set_alpha(0.4)\n",
    "\n",
    "def hover(event, fig, ax, line, annot):\n",
    "    vis = annot.get_visible()\n",
    "    if event.inaxes == ax:\n",
    "        cont, ind = line.contains(event)\n",
    "        if cont:\n",
    "            update_annot(ind, line, annot)\n",
    "            annot.set_visible(True)\n",
    "            fig.canvas.draw_idle()\n",
    "        else:\n",
    "            if vis:\n",
    "                annot.set_visible(False)\n",
    "                fig.canvas.draw_idle()\n",
    "\n",
    "def initialize_plot():\n",
    "    # Sample data\n",
    "    x = np.linspace(0, 10, 100)\n",
    "    y = np.sin(x)\n",
    "    \n",
    "    # Turn off interactive mode initially\n",
    "    plt.ioff()\n",
    "    \n",
    "    # Create the figure and axes\n",
    "    fig, axs = plt.subplots(1, 2, figsize=(14, 6))\n",
    "    \n",
    "    # Create the scatter plot on the first subplot\n",
    "    ax = axs[0]\n",
    "    line = ax.scatter(x, y)\n",
    "    \n",
    "    # Annotate point\n",
    "    annot = ax.annotate(\"\", xy=(0,0), xytext=(20,20),\n",
    "                        textcoords=\"offset points\",\n",
    "                        bbox=dict(boxstyle=\"round\", fc=\"w\"),\n",
    "                        arrowprops=dict(arrowstyle=\"->\"))\n",
    "    annot.set_visible(False)\n",
    "    \n",
    "    # Connect the hover event\n",
    "    fig.canvas.mpl_connect(\"motion_notify_event\", lambda event: hover(event, fig, ax, line, annot))\n",
    "\n",
    "    return fig, axs, ax, line, annot\n",
    "\n",
    "def plot_accuracy(ax, epochs, selected_results, none_selected_results, task_type_selected, task_type_non_selected):\n",
    "    ax.cla()\n",
    "    if task_type_selected == 'binary_classification':\n",
    "        ax.plot(epochs, selected_results['accuracy'], label='Selected Attributes (Accuracy)')\n",
    "    elif task_type_selected == 'regression':\n",
    "        ax.plot(epochs, selected_results['mse'], label='Selected Attributes (MSE)')\n",
    "    \n",
    "    if task_type_non_selected == 'binary_classification':\n",
    "        ax.plot(epochs, none_selected_results['accuracy'], label='Non-selected Attributes (Accuracy)')\n",
    "    elif task_type_non_selected == 'regression':\n",
    "        ax.plot(epochs, none_selected_results['mse'], label='Non-selected Attributes (MSE)')\n",
    "    \n",
    "    ax.set_title('Metrics over Epochs')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy/MSE')\n",
    "    ax.legend()\n",
    "\n",
    "def plot_f1_score(ax, epochs, selected_results, none_selected_results, task_type_selected, task_type_non_selected):\n",
    "    ax.cla()\n",
    "    if task_type_selected == 'binary_classification':\n",
    "        ax.plot(epochs, selected_results['f1_score'], label='Selected Attributes (F1 Score)')\n",
    "    elif task_type_selected == 'regression':\n",
    "        ax.plot(epochs, selected_results['mae'], label='Selected Attributes (MAE)')\n",
    "    \n",
    "    if task_type_non_selected == 'binary_classification':\n",
    "        ax.plot(epochs, none_selected_results['f1_score'], label='Non-selected Attributes (F1 Score)')\n",
    "    elif task_type_non_selected == 'regression':\n",
    "        ax.plot(epochs, none_selected_results['mae'], label='Non-selected Attributes (MAE)')\n",
    "    \n",
    "    ax.set_title('Metrics over Epochs')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('F1 Score/MAE')\n",
    "    ax.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score, mean_squared_error, mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _test_prediction_model(model, dataset, task_type, target_scale, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    target_scale = torch.tensor(target_scale, dtype = torch.float).to(device) if target_scale is not None else None\n",
    "    \n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for data, labels in dataloader:\n",
    "            data, labels = data.to(device), labels.to(device).float()\n",
    "            outputs = model(data)\n",
    "            \n",
    "            if task_type == 'binary_classification':\n",
    "                preds = torch.sigmoid(outputs).round()\n",
    "            elif task_type == 'regression':\n",
    "                preds =  target_scale*outputs\n",
    "\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "    \n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    \n",
    "    if task_type == 'binary_classification':\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "        return accuracy, f1\n",
    "    elif task_type == 'regression':\n",
    "        mse = mean_squared_error(all_labels, all_preds)\n",
    "        mae = mean_absolute_error(all_labels, all_preds)\n",
    "        return mse, mae\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction_models(epoch, axs, selected_classifier, none_selected_classifier, testset_selected, testset_none_selected, \n",
    "                            task_type_selected, task_type_non_selected, scale_selected, scale_none_selected, selected_results, none_selected_results, device):\n",
    "    print(f\"Testing causal classifier on selected attributes at epoch {epoch}...\")\n",
    "    selected_metrics = _test_prediction_model(selected_classifier, testset_selected, task_type_selected, scale_selected, device)\n",
    "    if task_type_selected == 'binary_classification':\n",
    "        selected_results['accuracy'].append(selected_metrics[0])\n",
    "        selected_results['f1_score'].append(selected_metrics[1])\n",
    "    elif task_type_selected == 'regression':\n",
    "        selected_results['mse'].append(selected_metrics[0])\n",
    "        selected_results['mae'].append(selected_metrics[1])\n",
    "\n",
    "    print(f\"Testing classifier on non-selected attributes at epoch {epoch}...\")\n",
    "    none_selected_metrics = _test_prediction_model(none_selected_classifier, testset_none_selected, task_type_non_selected, scale_none_selected, device)\n",
    "    if task_type_non_selected == 'binary_classification':\n",
    "        none_selected_results['accuracy'].append(none_selected_metrics[0])\n",
    "        none_selected_results['f1_score'].append(none_selected_metrics[1])\n",
    "    elif task_type_non_selected == 'regression':\n",
    "        none_selected_results['mse'].append(none_selected_metrics[0])\n",
    "        none_selected_results['mae'].append(none_selected_metrics[1])\n",
    "\n",
    "    # Update plots\n",
    "    if task_type_selected == 'binary_classification':\n",
    "        epochs = range(1, len(selected_results['accuracy']) + 1)\n",
    "    elif task_type_selected == 'regression':\n",
    "        epochs = range(1, len(selected_results['mse']) + 1)\n",
    "    plot_accuracy(axs[0], epochs, selected_results, none_selected_results, task_type_selected, task_type_non_selected)\n",
    "    plot_f1_score(axs[1], epochs, selected_results, none_selected_results, task_type_selected, task_type_non_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Function to train classifier\n",
    "DECAY_RATE = 0.01\n",
    "ITERATION_100K = 100000\n",
    "gamma = pow(DECAY_RATE, 1 / ITERATION_100K)\n",
    "\n",
    "def train_prediction_model(model, trainset, task_type, target_scale, num_epochs=3, gamma=gamma, device='cuda'):\n",
    "    model.train()\n",
    "    train_loader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "    len_loader = len(train_loader)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        sum_loss = 0\n",
    "        for data, labels in train_loader:\n",
    "            data, labels = data.to(device), labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)\n",
    "\n",
    "            if task_type == 'binary_classification':\n",
    "                # Using binary cross-entropy loss for binary classification\n",
    "                loss = torch.nn.functional.binary_cross_entropy_with_logits(outputs, labels)\n",
    "            elif task_type == 'regression':\n",
    "                if target_scale != None:\n",
    "                    scaled_labels = labels\n",
    "                else:\n",
    "                    scaled_labels = target_scale * labels\n",
    "                # Using mean squared error for regression\n",
    "                loss = torch.nn.functional.mse_loss(outputs, scaled_labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            sum_loss += loss.item()\n",
    "        \n",
    "        avg_loss = sum_loss / len_loader\n",
    "        print(f\"Epoch: {epoch + 1}, Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(f\"Final Learning rate: {optimizer.param_groups[0]['lr']:.8f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed random seed for reproducibility of experiments\n",
    "from nn.utils.init import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "# Importing configuration setups for ML parameters and data\n",
    "import torch\n",
    "from tools.setting.ml_params import MLParameters\n",
    "from tools.setting.data_config import DataConfig\n",
    "from trainer_hub import TrainerHub as CasualTrainer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "def initialize_causal_trainer(task_type, target_scale):  \n",
    "    num_classes = 1\n",
    "\n",
    "    # Configuration for the data handling, defining dataset specifics and the task type\n",
    "    data_config = DataConfig(dataset_name='CreditCardFraudDetection', task_type=task_type, obs_shape=[num_features], \n",
    "                            label_size=1, label_scale= target_scale, explain_size=num_features - num_classes)\n",
    "\n",
    "    # Initializing ML parameters without a core model and setting the encoder model to 'tabnet' with specific configurations\n",
    "    ml_params = MLParameters(ccnet_network='tabnet', encoder_network='none')\n",
    "\n",
    "    # Setting training parameters and device configuration\n",
    "    ml_params.training.num_epoch = 1\n",
    "    ml_params.model.ccnet_config.num_layers = 4\n",
    "    ml_params.algorithm.error_function = 'mse'\n",
    "\n",
    "    # Create a TrainerHub instance to manage training and data processing\n",
    "    causal_trainer = CasualTrainer(ml_params, data_config, device, use_print=True, use_wandb=False)\n",
    "    \n",
    "    return causal_trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_causal_and_prediction_models(X, selected_y, non_selected_y, task_type_selected, task_type_non_selected, scale_selected, scale_non_selected, num_epoch = 5):\n",
    "    # Split data for \"selected\" target\n",
    "    train_x_selected, test_x_selected, train_y_selected, test_y_selected = train_test_split(\n",
    "        X, selected_y, test_size=0.5, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Split data for \"non_selected\" target\n",
    "    train_x_non_selected, test_x_non_selected, train_y_non_selected, test_y_non_selected = train_test_split(\n",
    "        X, non_selected_y, test_size=0.5, shuffle=False\n",
    "    )\n",
    "\n",
    "    # Create LabeledDataset instances\n",
    "    causal_model_dataset = LabeledDataset(train_x_selected, train_y_selected)\n",
    "\n",
    "    # Initialize causal trainer\n",
    "    causal_trainer = initialize_causal_trainer(task_type_selected, scale_selected)\n",
    "\n",
    "    # Initialize the plot\n",
    "    fig, axs, ax, line, annot = initialize_plot()\n",
    "\n",
    "    # Create dictionaries to store results\n",
    "    selected_results_dict = {'accuracy': [], 'f1_score': [], 'mse': [], 'mae': []}\n",
    "    non_selected_results_dict = {'accuracy': [], 'f1_score': [], 'mse': [], 'mae': []}\n",
    "\n",
    "    for epoch in range(num_epoch):\n",
    "        if epoch > 0:\n",
    "            print(f\"Training causal model at epoch {epoch}...\")\n",
    "            causal_trainer.train(causal_model_dataset)\n",
    "        causal_model = causal_trainer.ccnet\n",
    "\n",
    "        selected_prediction_model = PredictionModel(causal_model.explain_size, 1, task_type=task_type_selected).to(device)\n",
    "        non_selected_prediction_model = PredictionModel(causal_model.explain_size, 1, task_type=task_type_non_selected).to(device)\n",
    "\n",
    "        # Train and evaluate classifiers on the explanation datasets\n",
    "        print(\"Training causal classifier on selected attributes...\")\n",
    "        train_explain_selected = causal_model.explain(train_x_selected.to(device))\n",
    "        trainset_explain_selected = LabeledDataset(train_explain_selected.detach().cpu(), train_y_selected)\n",
    "        test_explain_selected = causal_model.explain(test_x_selected.to(device))\n",
    "        testset_explain_selected = LabeledDataset(test_explain_selected.detach().cpu(), test_y_selected)\n",
    "        train_prediction_model(selected_prediction_model, trainset_explain_selected, task_type_selected, scale_selected, device = device)\n",
    "\n",
    "        print(\"Training classifier on non-selected attributes...\")\n",
    "        train_explain_non_selected = causal_model.explain(train_x_non_selected.to(device))\n",
    "        trainset_explain_non_selected = LabeledDataset(train_explain_non_selected.detach().cpu(), train_y_non_selected)\n",
    "        test_explain_non_selected = causal_model.explain(test_x_non_selected.to(device))\n",
    "        testset_explain_non_selected = LabeledDataset(test_explain_non_selected.detach().cpu(), test_y_non_selected)\n",
    "        train_prediction_model(non_selected_prediction_model, trainset_explain_non_selected, task_type_non_selected, scale_non_selected, device = device)\n",
    "\n",
    "        # Test classifiers\n",
    "        test_prediction_models(epoch, axs, \n",
    "                               selected_prediction_model, non_selected_prediction_model,\n",
    "                               testset_explain_selected, testset_explain_non_selected,\n",
    "                               task_type_selected, task_type_non_selected, \n",
    "                               scale_selected, scale_non_selected, \n",
    "                               selected_results_dict, non_selected_results_dict, \n",
    "                               device)\n",
    "\n",
    "        # Update the plot\n",
    "        display_plot(fig)\n",
    "\n",
    "    plt.ioff()  # Turn off interactive mode\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_causal_and_prediction_models(X, y_class, y_amount, task_type_class, task_type_amount, scale_class, scale_amount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_causal_and_prediction_models(X, y_amount, y_class, task_type_amount, task_type_class, scale_amount, scale_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Credit Card Fraud Detection: Handling Imbalanced Dataset with CCNet\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This tutorial explores the use of a Cooperative Network (CCNet) to address challenges associated with imbalanced datasets in the domain of credit card fraud detection. By leveraging the power of data generation, we aim to enhance the diversity and volume of training data, thereby improving the robustness and accuracy of models designed to identify fraudulent transactions.\n",
    "\n",
    "## Tutorial Goals\n",
    "\n",
    "The objectives of this tutorial are designed to guide you through the process of enhancing data quality and model performance:\n",
    "\n",
    "### Dataset Recreation with CCNet\n",
    "- **Understand Data Augmentation**: Learn how encoding techniques can be used to generate synthetic data instances that closely mimic the characteristics of real-world fraudulent and non-fraudulent transactions.\n",
    "- **Impact on Model Training**: Assess how augmenting the dataset influences the training process and subsequently, the model's ability to generalize from training to real-world scenarios.\n",
    "\n",
    "### Model Training and Evaluation\n",
    "- **Dual Model Training**: Train two distinct models to directly compare performance metrics:\n",
    "  - A model trained on the **original dataset**.\n",
    "  - A model trained on the **CCNet-augmented dataset**.\n",
    "- **Performance Metrics**: Use the F1 score, a critical measure for models operating on imbalanced datasets, to evaluate and compare the effectiveness of these models.\n",
    "\n",
    "### Testing and Validation\n",
    "- **Independent Model Testing**: Conduct a thorough evaluation of both models using a standalone test set that was not involved in the training phase.\n",
    "- **Objective Analysis**: Critically analyze the outcomes to validate whether data augmentation through CCNet offers a tangible benefit in detecting credit card fraud.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "By the end of this tutorial, participants will not only grasp the theoretical underpinnings of using synthetic data to combat data imbalance but also gain hands-on experience in applying these concepts through CCNet to potentially enhance model performance in fraud detection tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed random seed for reproducibility of experiments\n",
    "from nn.utils.init import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "# Importing configuration setups for ML parameters and data\n",
    "import torch\n",
    "from tools.setting.ml_params import MLParameters\n",
    "from tools.setting.data_config import DataConfig\n",
    "from trainer_hub import TrainerHub\n",
    "\n",
    "# Configuration for the data handling, defining dataset specifics and the task type\n",
    "data_config = DataConfig(dataset_name='CreditCardFraudDetection', task_type='binary_classification', obs_shape=[num_features], label_size=1, explain_size=num_features - 1)\n",
    "\n",
    "# Initializing ML parameters without a core model and setting the encoder model to 'tabnet' with specific configurations\n",
    "ml_params = MLParameters(ccnet_network='tabnet', encoder_network='none')\n",
    "\n",
    "# Setting training parameters and device configuration\n",
    "ml_params.training.num_epoch = 4\n",
    "ml_params.model.ccnet_config.num_layers = 4\n",
    "ml_params.algorithm.error_function = 'mse'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Create a TrainerHub instance to manage training and data processing\n",
    "trainer_hub = TrainerHub(ml_params, data_config, device, use_print=True, use_wandb=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(X, test_size=0.5, shuffle=False)\n",
    "y_train, y_test = train_test_split(y_class, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Labeled datasets for supervised learning tasks\n",
    "trainset = LabeledDataset(X_train, y_train)  # Corrected to include training data\n",
    "testset = LabeledDataset(X_test, y_test)     # Test set with proper labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_hub.train(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tools.loader import collate_fn\n",
    "\n",
    "len_trainset = len(trainset)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset, batch_size=256, collate_fn=collate_fn, shuffle=False)\n",
    "causal_model = trainer_hub.ccnet\n",
    "# Initialize the recreated dataset container\n",
    "\n",
    "# Generate synthetic data through the model to augment the training dataset\n",
    "data = X_train.to(device)\n",
    "# Generate a large amount of synthetic data\n",
    "explain = causal_model.explain(data)\n",
    "\n",
    "generated_data, generated_label = causal_model.generate(explain)\n",
    "\n",
    "recreated_training_data = generated_data.squeeze(1).detach().cpu()\n",
    "recreated_labels = generated_label.detach().cpu().argmax(dim=-1).unsqueeze(-1)\n",
    "\n",
    "\n",
    "print(f\"Recreated Training Data Shape: {recreated_training_data.shape}\")\n",
    "print(f\"Recreated Labels Shape: {recreated_labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Assuming recreated_dataset is a PyTorch tensor already available in your context\n",
    "ccnet_recreated_dataset = LabeledDataset(recreated_training_data.numpy(), recreated_labels.numpy())\n",
    "\n",
    "# Print the shapes of the datasets for verification\n",
    "print(f\"Labeled Original Trainset Shape: {len(trainset)}, {trainset.x.shape[1]}\")\n",
    "print(f\"CCNet Recreated Dataset Shape: {len(ccnet_recreated_dataset)}, {ccnet_recreated_dataset.x.shape[1]}\")\n",
    "\n",
    "print(f\"Labeled Original Testset Shape: {len(testset)}, {testset.x.shape[1]}\")\n",
    "\n",
    "# Retrieve number of features and classes from the recreated dataset\n",
    "num_features = recreated_training_data.shape[1]\n",
    "num_classes = recreated_labels.shape[1]\n",
    "\n",
    "print(f\"Number of Features: {num_features}\")\n",
    "print(f\"Number of Classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised_model(model, dataset, num_epoch=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    # Initialize the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # Ensure reproducibility by resetting the random seed\n",
    "    # Create DataLoader for batch processing\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    # Training loop\n",
    "    for epoch in range(num_epoch):  # Train for 2 epochs as an example\n",
    "        for i, (data, label) in enumerate(trainloader):\n",
    "            data = data.to(device).clone().detach()\n",
    "            label = label.to(device).float()\n",
    "            # Perform forward pass\n",
    "            output = model(data)\n",
    "            # Compute loss\n",
    "            loss = torch.nn.functional.binary_cross_entropy(output, label)\n",
    "            # Backward pass to compute gradients\n",
    "            loss.backward()\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train a model on the recreated dataset\n",
    "model_trained_on_recreated = PredictionModel(input_size=num_features, output_size=num_classes, task_type='binary_classification').to(device)\n",
    "train_supervised_model(model_trained_on_recreated, ccnet_recreated_dataset)\n",
    "\n",
    "# Initialize and train a model on the original dataset\n",
    "model_trained_on_original = PredictionModel(input_size=num_features, output_size=num_classes, task_type='binary_classification').to(device)\n",
    "train_supervised_model(model_trained_on_original, trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def get_f1_score(model, testset, batch_size=256):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # DataLoader for testing\n",
    "    test_loader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # No gradient computation needed during inference\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(data)\n",
    "            # Process output for binary classification\n",
    "            predicted = (output.squeeze() > 0.5).long()\n",
    "            y_true.extend(label.squeeze().long().cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Compute and return the F1 score\n",
    "    score = f1_score(y_true, y_pred, average='binary')\n",
    "    return score\n",
    "\n",
    "# Calculate F1 scores for both models\n",
    "f1_score_original = get_f1_score(model_trained_on_original, testset)\n",
    "f1_score_recreated = get_f1_score(model_trained_on_recreated, testset)\n",
    "\n",
    "# Output the results\n",
    "print(\"F1 score of the supervised learning model trained on the original data: \", f1_score_original)\n",
    "print(\"F1 score of the supervised learning model trained on the recreated data: \", f1_score_recreated)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
