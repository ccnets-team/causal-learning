{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "Author:\n",
    "        \n",
    "        PARK, JunHo, junho@ccnets.org\n",
    "\n",
    "        \n",
    "        KIM, JoengYoong, jeongyoong@ccnets.org\n",
    "        \n",
    "    COPYRIGHT (c) 2024. CCNets. All Rights reserved.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cheat Your Decision-Making Model: Manipulating Loan Approval Data with Causal Inference\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this tutorial, we explore how to manipulate decision-making models for loan approval prediction. Using a Cooperative Network (CCNet), we investigate the impact of subtle manipulations in non-fraudulent data to test and expose the vulnerabilities of machine learning models. This demonstration not only highlights the strengths and weaknesses of current fraud detection systems but also outlines the ethical considerations and potential risks associated with data manipulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial Goals\n",
    "This tutorial offers guidance on applying data manipulation to machine learning models for predicting loan approval outcomes and evaluating the impacts. We will address the following:\n",
    "\n",
    "1. **Training a Binary Classifier**: We'll train a model using actual loan data to differentiate between approved and denied loan applications.\n",
    "2. **Generating Manipulated Data with CCNet**: We'll employ the Explainer, Reasoner, and Producer networks within CCNet to create data that mimics genuine loan applications but is engineered to mislead the classifier by altering decision label factors.\n",
    "3. **Evaluating Classifier Performance**: We'll test the classifier on both the original and the manipulated datasets to assess the model’s robustness. The classifier should perform well on both the original test set and the CCNet-recreated test set, demonstrating that CCNet has effectively learned how the classifier maps decisions.\n",
    "4. **Comparative Dataset Analysis**:\n",
    "   - Testset A: Real Test Data - Actual loan approval data used as a benchmark to evaluate the classifier’s performance.\n",
    "   - Testset B: CCNet-generated data with random labels but maintaining the same frequency distribution as the original. The classifier's performance on this dataset should mirror that of Testset A, indicating that CCNet comprehends the classifier's decision-making process.\n",
    "   - Testset C: CCNet-generated data with original labels. While Testset B proves that CCNet can generate a genuine data distribution for any scenario of decision label, most of the data's information resides in the explanation vector, making it easy to manipulate by changing the decision factor of the data. In short, the decision-making process can be easily manipulated through causal inference.\n",
    "5. **Ethical Considerations**: We will discuss the ethical implications of manipulating data in machine learning, emphasizing the necessity for robustness in model training and the risks of misuse in critical applications like loan approval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "path_append = \"../\"\n",
    "sys.path.append(path_append)  # Go up one directory from where you are.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_id</th>\n",
       "      <th>no_of_dependents</th>\n",
       "      <th>education</th>\n",
       "      <th>self_employed</th>\n",
       "      <th>income_annum</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>cibil_score</th>\n",
       "      <th>residential_assets_value</th>\n",
       "      <th>commercial_assets_value</th>\n",
       "      <th>luxury_assets_value</th>\n",
       "      <th>bank_asset_value</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>9600000</td>\n",
       "      <td>29900000</td>\n",
       "      <td>12</td>\n",
       "      <td>778</td>\n",
       "      <td>2400000</td>\n",
       "      <td>17600000</td>\n",
       "      <td>22700000</td>\n",
       "      <td>8000000</td>\n",
       "      <td>Approved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4100000</td>\n",
       "      <td>12200000</td>\n",
       "      <td>8</td>\n",
       "      <td>417</td>\n",
       "      <td>2700000</td>\n",
       "      <td>2200000</td>\n",
       "      <td>8800000</td>\n",
       "      <td>3300000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>9100000</td>\n",
       "      <td>29700000</td>\n",
       "      <td>20</td>\n",
       "      <td>506</td>\n",
       "      <td>7100000</td>\n",
       "      <td>4500000</td>\n",
       "      <td>33300000</td>\n",
       "      <td>12800000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>8200000</td>\n",
       "      <td>30700000</td>\n",
       "      <td>8</td>\n",
       "      <td>467</td>\n",
       "      <td>18200000</td>\n",
       "      <td>3300000</td>\n",
       "      <td>23300000</td>\n",
       "      <td>7900000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9800000</td>\n",
       "      <td>24200000</td>\n",
       "      <td>20</td>\n",
       "      <td>382</td>\n",
       "      <td>12400000</td>\n",
       "      <td>8200000</td>\n",
       "      <td>29400000</td>\n",
       "      <td>5000000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4264</th>\n",
       "      <td>4265</td>\n",
       "      <td>5</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1000000</td>\n",
       "      <td>2300000</td>\n",
       "      <td>12</td>\n",
       "      <td>317</td>\n",
       "      <td>2800000</td>\n",
       "      <td>500000</td>\n",
       "      <td>3300000</td>\n",
       "      <td>800000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4265</th>\n",
       "      <td>4266</td>\n",
       "      <td>0</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3300000</td>\n",
       "      <td>11300000</td>\n",
       "      <td>20</td>\n",
       "      <td>559</td>\n",
       "      <td>4200000</td>\n",
       "      <td>2900000</td>\n",
       "      <td>11000000</td>\n",
       "      <td>1900000</td>\n",
       "      <td>Approved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4266</th>\n",
       "      <td>4267</td>\n",
       "      <td>2</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>6500000</td>\n",
       "      <td>23900000</td>\n",
       "      <td>18</td>\n",
       "      <td>457</td>\n",
       "      <td>1200000</td>\n",
       "      <td>12400000</td>\n",
       "      <td>18100000</td>\n",
       "      <td>7300000</td>\n",
       "      <td>Rejected</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4267</th>\n",
       "      <td>4268</td>\n",
       "      <td>1</td>\n",
       "      <td>Not Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>4100000</td>\n",
       "      <td>12800000</td>\n",
       "      <td>8</td>\n",
       "      <td>780</td>\n",
       "      <td>8200000</td>\n",
       "      <td>700000</td>\n",
       "      <td>14100000</td>\n",
       "      <td>5800000</td>\n",
       "      <td>Approved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4268</th>\n",
       "      <td>4269</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate</td>\n",
       "      <td>No</td>\n",
       "      <td>9200000</td>\n",
       "      <td>29700000</td>\n",
       "      <td>10</td>\n",
       "      <td>607</td>\n",
       "      <td>17800000</td>\n",
       "      <td>11800000</td>\n",
       "      <td>35700000</td>\n",
       "      <td>12000000</td>\n",
       "      <td>Approved</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4269 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      loan_id  no_of_dependents      education self_employed  income_annum  \\\n",
       "0           1                 2       Graduate            No       9600000   \n",
       "1           2                 0   Not Graduate           Yes       4100000   \n",
       "2           3                 3       Graduate            No       9100000   \n",
       "3           4                 3       Graduate            No       8200000   \n",
       "4           5                 5   Not Graduate           Yes       9800000   \n",
       "...       ...               ...            ...           ...           ...   \n",
       "4264     4265                 5       Graduate           Yes       1000000   \n",
       "4265     4266                 0   Not Graduate           Yes       3300000   \n",
       "4266     4267                 2   Not Graduate            No       6500000   \n",
       "4267     4268                 1   Not Graduate            No       4100000   \n",
       "4268     4269                 1       Graduate            No       9200000   \n",
       "\n",
       "      loan_amount  loan_term  cibil_score  residential_assets_value  \\\n",
       "0        29900000         12          778                   2400000   \n",
       "1        12200000          8          417                   2700000   \n",
       "2        29700000         20          506                   7100000   \n",
       "3        30700000          8          467                  18200000   \n",
       "4        24200000         20          382                  12400000   \n",
       "...           ...        ...          ...                       ...   \n",
       "4264      2300000         12          317                   2800000   \n",
       "4265     11300000         20          559                   4200000   \n",
       "4266     23900000         18          457                   1200000   \n",
       "4267     12800000          8          780                   8200000   \n",
       "4268     29700000         10          607                  17800000   \n",
       "\n",
       "      commercial_assets_value  luxury_assets_value  bank_asset_value  \\\n",
       "0                    17600000             22700000           8000000   \n",
       "1                     2200000              8800000           3300000   \n",
       "2                     4500000             33300000          12800000   \n",
       "3                     3300000             23300000           7900000   \n",
       "4                     8200000             29400000           5000000   \n",
       "...                       ...                  ...               ...   \n",
       "4264                   500000              3300000            800000   \n",
       "4265                  2900000             11000000           1900000   \n",
       "4266                 12400000             18100000           7300000   \n",
       "4267                   700000             14100000           5800000   \n",
       "4268                 11800000             35700000          12000000   \n",
       "\n",
       "     loan_status  \n",
       "0       Approved  \n",
       "1       Rejected  \n",
       "2       Rejected  \n",
       "3       Rejected  \n",
       "4       Rejected  \n",
       "...          ...  \n",
       "4264    Rejected  \n",
       "4265    Approved  \n",
       "4266    Rejected  \n",
       "4267    Approved  \n",
       "4268    Approved  \n",
       "\n",
       "[4269 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/datasets/architsharma01/loan-approval-prediction-dataset\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "dataroot = path_append + \"../data/LoanApprovalPredictionDataset/loan_approval_dataset.csv\"\n",
    "df = pd.read_csv(dataroot)\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approved 62.22 %of the dataset\n",
      "Rejected 37.78 %of the dataset\n"
     ]
    }
   ],
   "source": [
    "print('Approved', round(df['loan_status'].value_counts()[0] / len(df) *100,2), '%of the dataset')\n",
    "print('Rejected', round(df['loan_status'].value_counts()[1] / len(df) *100,2), '%of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "one_hot_columns = ['education', 'self_employed']\n",
    "\n",
    "df = pd.get_dummies(df, columns=one_hot_columns)\n",
    "\n",
    "one_hot_columns = ['education_ Graduate', 'education_ Not Graduate', 'self_employed_ No', 'self_employed_ Yes']\n",
    "df[one_hot_columns] = df[one_hot_columns].astype(int)\n",
    "\n",
    "scale_cols = ['loan_id', 'no_of_dependents', 'income_annum', 'loan_amount',\n",
    "       'loan_term', 'cibil_score', 'residential_assets_value',\n",
    "       'commercial_assets_value', 'luxury_assets_value', 'bank_asset_value']\n",
    "\n",
    "# Initialize scalers\n",
    "sc = RobustScaler()\n",
    "\n",
    "# Scale all columns except the last one (which is the class column)\n",
    "df[scale_cols] = sc.fit_transform(df[scale_cols])\n",
    "\n",
    "# Map the target column to 0 and 1\n",
    "df['loan_status'] = df['loan_status'].map({' Approved': 1, ' Rejected': 0})\n",
    "\n",
    "# Drop the loan_id column\n",
    "df.drop('loan_id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the original loan_status column to change its position\n",
    "loan_status = df.pop('loan_status')\n",
    "\n",
    "df['loan_status'] = loan_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_dependents</th>\n",
       "      <th>income_annum</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>cibil_score</th>\n",
       "      <th>residential_assets_value</th>\n",
       "      <th>commercial_assets_value</th>\n",
       "      <th>luxury_assets_value</th>\n",
       "      <th>bank_asset_value</th>\n",
       "      <th>education_ Graduate</th>\n",
       "      <th>education_ Not Graduate</th>\n",
       "      <th>self_employed_ No</th>\n",
       "      <th>self_employed_ Yes</th>\n",
       "      <th>loan_status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>1.115942</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.603390</td>\n",
       "      <td>-0.351648</td>\n",
       "      <td>2.206349</td>\n",
       "      <td>0.570423</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.208333</td>\n",
       "      <td>-0.166667</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.620339</td>\n",
       "      <td>-0.318681</td>\n",
       "      <td>-0.238095</td>\n",
       "      <td>-0.408451</td>\n",
       "      <td>-0.270833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.101449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.318644</td>\n",
       "      <td>0.164835</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>1.316901</td>\n",
       "      <td>1.708333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.645833</td>\n",
       "      <td>1.173913</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.450847</td>\n",
       "      <td>1.384615</td>\n",
       "      <td>-0.063492</td>\n",
       "      <td>0.612676</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.702899</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.738983</td>\n",
       "      <td>0.747253</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.042254</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_of_dependents  income_annum  loan_amount  loan_term  cibil_score  \\\n",
       "0         -0.333333      0.937500     1.115942        0.2     0.603390   \n",
       "1         -1.000000     -0.208333    -0.166667       -0.2    -0.620339   \n",
       "2          0.000000      0.833333     1.101449        1.0    -0.318644   \n",
       "3          0.000000      0.645833     1.173913       -0.2    -0.450847   \n",
       "4          0.666667      0.979167     0.702899        1.0    -0.738983   \n",
       "\n",
       "   residential_assets_value  commercial_assets_value  luxury_assets_value  \\\n",
       "0                 -0.351648                 2.206349             0.570423   \n",
       "1                 -0.318681                -0.238095            -0.408451   \n",
       "2                  0.164835                 0.126984             1.316901   \n",
       "3                  1.384615                -0.063492             0.612676   \n",
       "4                  0.747253                 0.714286             1.042254   \n",
       "\n",
       "   bank_asset_value  education_ Graduate  education_ Not Graduate  \\\n",
       "0          0.708333                    1                        0   \n",
       "1         -0.270833                    0                        1   \n",
       "2          1.708333                    1                        0   \n",
       "3          0.687500                    1                        0   \n",
       "4          0.083333                    0                        1   \n",
       "\n",
       "   self_employed_ No  self_employed_ Yes  loan_status  \n",
       "0                  1                   0            1  \n",
       "1                  0                   1            0  \n",
       "2                  1                   0            0  \n",
       "3                  1                   0            0  \n",
       "4                  0                   1            0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the labeled and unlabeled dataset classes\n",
    "class LabeledDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        vals = torch.tensor(self.x[index], dtype=torch.float32)\n",
    "        label = torch.tensor(self.y[index], dtype=torch.long)\n",
    "        # label = torch.nn.functional.one_hot(label, num_classes=2).float().squeeze(0)\n",
    "        return vals, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Splitting for Training and Testing\n",
    "\n",
    "The original dataset is split into training and testing parts to evaluate the model's performance accurately. This step is crucial for validating the effectiveness of the training on unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled Trainset Shape: 1280, 13\n",
      "Labeled Testset Shape: 2989, 13\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and test sets for model evaluation\n",
    "df_train, df_test = train_test_split(df, test_size=0.7, shuffle=True, random_state=42)\n",
    "X_train, y_train = df_train.iloc[:, :-1].values, df_train.iloc[:, -1:].values\n",
    "X_test, y_test = df_test.iloc[:, :-1].values, df_test.iloc[:, -1:].values\n",
    "\n",
    "# Labeled datasets for supervised learning tasks\n",
    "trainset = LabeledDataset(X_train, y_train)  # Corrected to include training data\n",
    "testset = LabeledDataset(X_test, y_test)     # Test set with proper labels\n",
    "\n",
    "# Printing the shapes of the datasets for verification\n",
    "print(f\"Labeled Trainset Shape: {len(trainset)}, {trainset.x.shape[1]}\")\n",
    "print(f\"Labeled Testset Shape: {len(testset)}, {testset.x.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 1\n"
     ]
    }
   ],
   "source": [
    "# Calculate the number of features and classes\n",
    "n_features = trainset[0][0].shape[0]\n",
    "n_classes = trainset[0][1].shape[0]\n",
    "\n",
    "print(n_features, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Setup and Model Configuration\n",
    "\n",
    "This section initializes the environment by setting a fixed random seed to ensure reproducibility of results. It imports necessary configurations and initializes model parameters with specific configurations. The model specified here is set to have no core model but uses a 'tabnet' encoder model for data processing, which is particularly tailored for structured or tabular data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a fixed random seed for reproducibility of experiments\n",
    "from nn.utils.init import set_random_seed\n",
    "set_random_seed(0)\n",
    "\n",
    "# Importing configuration setups for ML parameters and data\n",
    "import torch\n",
    "from tools.setting.ml_params import MLParameters\n",
    "from tools.setting.data_config import DataConfig\n",
    "from trainer_hub import TrainerHub\n",
    "\n",
    "# Configuration for the data handling, defining dataset specifics and the task type\n",
    "data_config = DataConfig(dataset_name='LoanApproval', task_type='binary_classification', obs_shape=[n_features], label_size=n_classes, explain_size=4)\n",
    "\n",
    "# Initializing ML parameters without a core model and setting the encoder model to 'tabnet' with specific configurations\n",
    "ml_params = MLParameters(ccnet_network='tabnet', encoder_network='none')\n",
    "\n",
    "# Setting training parameters and device configuration\n",
    "ml_params.training.num_epoch = 50\n",
    "ml_params.model.ccnet_config.num_layers = 3\n",
    "ml_params.algorithm.error_function = 'mse'\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Create a TrainerHub instance to manage training and data processing\n",
    "trainer_hub = TrainerHub(ml_params, data_config, device, use_print=True, use_wandb=False, print_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d040a979244479db08cc489e26becf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ea2f2c28b440aca5a840d1d33d3d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dacba4c5fa3549f1bac18bd4d63f087d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "833fb8cd6f4a44499ef51bf1fdb2ebd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fd5d7bf9bde4c148fe45605a882e3b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf5a164c8184a8499c17a91137fcaf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "539d304576e64f5fa9fcfbddb318cf7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e697f4d5f67448e90293d3ec2bf44fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32176443894c4af5a5737d2664ba5a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277d17d4e3874e65824c26d0f5d44b47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4e91cbad8e4bdcaf8cc3e9e62eef79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb2da66dece2433cac0e4cb63d8c773a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/50][0/20][Time 25.66]\n",
      "Unified LR across all optimizers: 0.00019815726328921765\n",
      "--------------------Training Metrics--------------------\n",
      "Cooperative Network(core):  Three Tabnet\n",
      "Inf: 0.1212\tGen: 0.3599\tRec: 0.3548\tE: 0.0461\tR: 0.0385\tP: 0.3983\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8828\n",
      "precision: 0.8200\n",
      "recall: 0.8723\n",
      "f1_score: 0.8454\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb80dc54a909431796b4a01abbbe6a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19bb8f0d4484c0185586c095b12038f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef4c5b9f5dd4173af8bcb50c07dac37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e45229491745d48829617d027e80ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2fa83716c949ff851bbd71ee0ed8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8ca4e3ecf54e54b0590e0b8d9bcc77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab2d515eac240abb81f6748802566d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ab484bb9f5423babf9712fe72a938c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd24e4f383440199aac3dbb809d8ff9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7fc4bd451a64f32aeb7b3ea5468e0ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/50][0/20][Time 24.75]\n",
      "Unified LR across all optimizers: 0.00019634054657948372\n",
      "--------------------Training Metrics--------------------\n",
      "Cooperative Network(core):  Three Tabnet\n",
      "Inf: 0.0505\tGen: 0.2745\tRec: 0.2712\tE: 0.0102\tR: 0.0069\tP: 0.2745\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8906\n",
      "precision: 0.8247\n",
      "recall: 0.8791\n",
      "f1_score: 0.8511\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c5ebbea1434aef99782873abecf625",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "118d0271f9914eb38b22fb60d197c52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87cec62fc5e74330852eda7f2060712c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d159356c984123be456e3dce10805e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45bfeacfb04c4543bafa1c4f418d5aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb71df69fd3f4e948541f253f599ece4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa560602e89f42b7b7dfdac58be48427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd88173b0f5e486fa6eb280e61db8549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db3e0bf3921c4815aa12a8d0fc7765a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d53fad853a46df977072c4ce6e9968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/50][0/20][Time 25.56]\n",
      "Unified LR across all optimizers: 0.00019454048562865856\n",
      "--------------------Training Metrics--------------------\n",
      "Cooperative Network(core):  Three Tabnet\n",
      "Inf: 0.0368\tGen: 0.2521\tRec: 0.2491\tE: 0.0065\tR: 0.0040\tP: 0.2415\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.9062\n",
      "precision: 0.8605\n",
      "recall: 0.8605\n",
      "f1_score: 0.8605\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78caa85d722442a6b9c68559dcfd2001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37a4092f6a784aa6a67c6893c5bb99d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac71c0d98913458ba534621c448a5d8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c5c6dfd68024b81890c606aaac70fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351df900438049029d9dc81997237891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0396ca5447d449c38ea39f3c0caaa322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14c3025c97ee4e8caedf652fde75c0c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6298217c2209439195d93d9547f2215c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879898a33dc54e8487e12bb3b76a2985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0840ec99de43e3b5c6b92d2f15113e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40/50][0/20][Time 25.42]\n",
      "Unified LR across all optimizers: 0.00019275692773582703\n",
      "--------------------Training Metrics--------------------\n",
      "Cooperative Network(core):  Three Tabnet\n",
      "Inf: 0.0339\tGen: 0.2395\tRec: 0.2370\tE: 0.0054\tR: 0.0036\tP: 0.2190\n",
      "--------------------Test Metrics------------------------\n",
      "accuracy: 0.8945\n",
      "precision: 0.8526\n",
      "recall: 0.8617\n",
      "f1_score: 0.8571\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79eb8443d0c44b4282ad4da5005a2ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f4af62972f048e38b2d03dca423548a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "402f4c6462b340269fadfb89875e072a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6b10c4b4f644cd7a44580020e64ac53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ab7d3b70a841cdb209fb1601d336d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26065af4c52d4e2ea97bf489818817f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0bdb8208d69446f89f7eab1b5944830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66a9cbd9083d4604ae21be594e593f7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e46ecb09ae4b1abd357acd0d728aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iterations:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generation loss should close to 0.0\n",
    "load_model = False\n",
    "if load_model:\n",
    "    trainer_hub.load_trainer(ccnet_network = True)\n",
    "else:\n",
    "    trainer_hub.train(trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manipulated Data Shape: torch.Size([2989, 13])\n",
      "Reversed Labels Shape: torch.Size([2989, 1])\n",
      "Original Labels Shape: torch.Size([2989, 1])\n"
     ]
    }
   ],
   "source": [
    "# DataLoader for processing training data in larger batches without shuffling\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset, batch_size=256, shuffle=False, drop_last=False)\n",
    "\n",
    "# CCNet setup for generating synthetic manipulated data\n",
    "ccnet = trainer_hub.ccnet\n",
    "manipulated_data = None\n",
    "random_labels = None\n",
    "original_labels = None\n",
    "probability_positive = 0.6222 # 62.2% of the data is positive\n",
    "\n",
    "# Generate synthetic data to enhance the diversity of the training dataset\n",
    "for data, labels in test_loader:\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Create random labels with 62.2% positive (1) and 37.8% negative (0) labels\n",
    "    random_label = (torch.rand(labels.size(0)).to(device) < probability_positive).float()\n",
    "    random_label = torch.nn.functional.one_hot(random_label.to(torch.int64), num_classes=2).float()\n",
    "\n",
    "    # Use CCNet to explain the original data and generate synthetic counterparts\n",
    "    explanations = ccnet.explain(data)\n",
    "    synthetic_data = ccnet.produce(random_label, explanations)\n",
    "    \n",
    "    # Detach synthetic data and labels from GPU for further processing\n",
    "    synthetic_data = synthetic_data.detach().cpu()\n",
    "    random_label = random_label.detach().cpu().argmax(dim=-1).unsqueeze(-1)\n",
    "    labels = labels.detach().cpu()\n",
    "\n",
    "    # Accumulate the generated data for analysis and training\n",
    "    if manipulated_data is None:\n",
    "        manipulated_data = synthetic_data\n",
    "        random_labels = random_label\n",
    "        original_labels = labels\n",
    "    else:\n",
    "        manipulated_data = torch.cat([manipulated_data, synthetic_data], dim=0)\n",
    "        random_labels = torch.cat([random_labels, random_label], dim=0)\n",
    "        original_labels = torch.cat([original_labels, labels], dim=0)\n",
    "\n",
    "# Output the shapes of the datasets for verification\n",
    "print(f\"Manipulated Data Shape: {manipulated_data.shape}\")\n",
    "print(f\"Reversed Labels Shape: {random_labels.shape}\")\n",
    "print(f\"Original Labels Shape: {original_labels.shape}\")\n",
    "\n",
    "# Create datasets for both synthetic and original label scenarios\n",
    "random_label_testset = LabeledDataset(manipulated_data.numpy(), random_labels.numpy())\n",
    "original_label_testset = LabeledDataset(manipulated_data.numpy(), original_labels.numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Supervised Models\n",
    "\n",
    "This section outlines the process of training supervised learning models using both original and synthetic datasets. The `train_supervised_model` function is designed to iterate through the dataset, perform forward passes, compute loss, and update model weights using backpropagation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_supervised_model(model, dataset, num_epoch=5):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "    # Initialize the optimizer\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    # Ensure reproducibility by resetting the random seed\n",
    "    # Create DataLoader for batch processing\n",
    "    trainloader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    # Training loop\n",
    "    for epoch in range(num_epoch):  # Train for 2 epochs as an example\n",
    "        for i, (data, label) in enumerate(trainloader):\n",
    "            data = data.to(device).clone().detach()\n",
    "            label = label.to(device).float()\n",
    "            # Perform forward pass\n",
    "            output = model(data)\n",
    "            # Compute loss\n",
    "            loss = torch.nn.functional.binary_cross_entropy(output, label)\n",
    "            # Backward pass to compute gradients\n",
    "            loss.backward()\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "            # Reset gradients\n",
    "            optimizer.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_layers=4, hidden_size=256):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Create a list to hold all layers\n",
    "        layers = []\n",
    "        \n",
    "        # Input layer\n",
    "        layers.append(torch.nn.Linear(input_size, hidden_size))\n",
    "        layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        # Hidden layers\n",
    "        for _ in range(num_layers - 2):\n",
    "            layers.append(torch.nn.Linear(hidden_size, hidden_size))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "        \n",
    "        # Output layer\n",
    "        layers.append(torch.nn.Linear(hidden_size, output_size))\n",
    "        \n",
    "        # Register all layers\n",
    "        self.layers = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layers(x)\n",
    "        return torch.sigmoid(x)\n",
    "    \n",
    "# Initialize and train a model on the recreated dataset\n",
    "decision_making_model = MLP(input_size=n_features, output_size=n_classes).to(device)\n",
    "train_supervised_model(decision_making_model, trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model Performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of the supervised learning model tested on the original data:  0.9380873410724158\n",
      "F1 score of the supervised learning model tested on the manipulated data with random label:  0.9989229940764675\n",
      "F1 score of the supervised learning model tested on the manipulated data with original label:  0.6257104194857915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def get_f1_score(model, input_testset, device, batch_size=64):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    # DataLoader for testing\n",
    "    test_loader = torch.utils.data.DataLoader(input_testset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # No gradient computation needed during inference\n",
    "    with torch.no_grad():\n",
    "        for data, label in test_loader:\n",
    "            data = data.to(device)\n",
    "            label = label.to(device)\n",
    "            output = model(data)\n",
    "            # Process output for binary classification\n",
    "            predicted = (output.squeeze() > 0.5).long()\n",
    "            y_true.extend(label.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # Compute and return the F1 score\n",
    "    score = f1_score(y_true, y_pred, average='binary')\n",
    "    return score\n",
    "\n",
    "# Calculate F1 scores for both models\n",
    "fraud_detection_f1_score = get_f1_score(decision_making_model, testset, device)\n",
    "random_testset_f1_score = get_f1_score(decision_making_model, random_label_testset, device)\n",
    "manipulated_testset_f1_score = get_f1_score(decision_making_model, original_label_testset, device)\n",
    "\n",
    "# Output the results\n",
    "print(\"F1 score of the supervised learning model tested on the original data: \", fraud_detection_f1_score)\n",
    "print(\"F1 score of the supervised learning model tested on the manipulated data with random label: \", random_testset_f1_score)\n",
    "print(\"F1 score of the supervised learning model tested on the manipulated data with original label: \", manipulated_testset_f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
