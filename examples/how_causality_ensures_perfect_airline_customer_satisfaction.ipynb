{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author:\n",
    "        \n",
    "        KIM, JeongYoong, jeongyoong@ccnets.org\n",
    "        \n",
    "    COPYRIGHT (c) 2024. CCNets. All Rights reserved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airline Passenger Satisfaction Classification\n",
    "\n",
    "https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction/data\n",
    "\n",
    "\n",
    "<p>\n",
    "    <img src=\"https://www.travelandleisure.com/thmb/h97kSvljd2QYH2nUy3Y9ZNgO_pw=/1500x0/filters:no_upscale():max_bytes(150000):strip_icc()/plane-data-BUSYROUTES1217-f4f84b08d47f4951b11c148cee2c3dea.jpg\" width=600>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path_append = \"../\"\n",
    "sys.path.append(path_append)  # Go up one directory from where you are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load  Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(path_append + '../data/Airline Customer Satisfaction/train.csv')\n",
    "df_test = pd.read_csv(path_append + '../data/Airline Customer Satisfaction/test.csv')\n",
    "df_train.head()\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check labels count\n",
    "df_train[['satisfaction']].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.preprocessing.data_frame import process_dataframe\n",
    "\n",
    "target_columns = ['satisfaction']\n",
    "drop_columns = ['Unnamed: 0','id']\n",
    "\n",
    "# Assuming df_train and df_test are your initial dataframes\n",
    "df_train_length = len(df_train)\n",
    "df_test_length = len(df_test)\n",
    "\n",
    "# Concatenate the dataframes\n",
    "df = pd.concat([df_train, df_test], axis=0)\n",
    "\n",
    "# Process the combined dataframe\n",
    "df, description_train = process_dataframe(df, target_columns, drop_columns=drop_columns)\n",
    "\n",
    "# Split the dataframe back into training and test sets\n",
    "df_train = df.iloc[:df_train_length]\n",
    "df_test = df.iloc[df_train_length:]\n",
    "\n",
    "num_features = description_train['num_features']\n",
    "num_classes = description_train['num_classes']\n",
    "\n",
    "print(f\"Number of features after scaling: {num_features}\")\n",
    "print(f\"Number of classes after scaling: {num_classes}\")\n",
    "description_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset Class\n",
    "class AirlineDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        vals = torch.tensor(self.x[index], dtype = torch.float32)\n",
    "        label = torch.tensor(self.y[index], dtype= torch.long)\n",
    "        return vals, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split the data into train, validation and test sets\n",
    "X_train, y_train = df_train.iloc[:, :-1].values, df_train.iloc[:, -1:].values\n",
    "X_test, y_test = df_test.iloc[:, :-1].values, df_test.iloc[:,-1:].values\n",
    "\n",
    "trainset = AirlineDataset(X_train, y_train)\n",
    "testset = AirlineDataset(X_test, y_test)\n",
    "\n",
    "print(f\"Labeled Trainset Shape: {len(trainset)}, {trainset.x.shape[1]}\")\n",
    "print(f\"Labeled Testset Shape: {len(testset)}, {testset.x.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features =  trainset.x.shape[1]\n",
    "num_classes =  trainset.y.shape[1]\n",
    "\n",
    "num_features, num_classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.setting.data_config import DataConfig\n",
    "from tools.setting.ml_params import MLParameters\n",
    "from trainer_hub import TrainerHub\n",
    "\n",
    "# Set the data configuration\n",
    "data_config = DataConfig(dataset_name = 'airline_satisfaction', task_type='binary_classification', obs_shape=[num_features], label_size=num_classes)\n",
    "\n",
    "#  Set the ML parameters\n",
    "ml_params = MLParameters(ccnet_network = 'tabnet', encoder_network = 'none')\n",
    "\n",
    "# Set the device to GPU if available, else CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "# Initialize the TrainerHub class with the training configuration, data configuration, device, and use_print and use_wandb flags\n",
    "trainer_hub = TrainerHub(ml_params, data_config, device, use_print=True, use_wandb=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_hub.train(trainset, testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_hub.test(testset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ccnets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
